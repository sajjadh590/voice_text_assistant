#!/usr/bin/env python3
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                           OMNI-HEAR AI v2.3                                  ‚ïë
‚ïë              Bilingual Telegram Bot - Fixed & Stable Version                 ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  üîÑ STABLE MODELS: Uses proven Gemini models                                 ‚ïë
‚ïë  üìù BETTER LOGGING: Shows exact error messages                               ‚ïë
‚ïë  üßπ MEMORY SAFE: Audio cache cleaned properly                                ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import os
import sys
import logging
import base64
import asyncio
import traceback
from typing import Optional, List, Tuple

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

# ============== LOGGING ==============
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ============== CONFIGURATION ==============
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ============== VALIDATE API KEY ==============
if not GEMINI_API_KEY:
    logger.error("‚ùå GEMINI_API_KEY is not set!")
    print("‚ö†Ô∏è  Please set GEMINI_API_KEY environment variable")
else:
    logger.info(f"‚úÖ GEMINI_API_KEY found: {GEMINI_API_KEY[:10]}...")
    genai.configure(api_key=GEMINI_API_KEY)

# ============== STABLE MODEL CASCADE ==============
# Using proven models that work reliably
MODEL_PRIORITY: List[str] = [
    "gemini-1.5-flash",      # Most stable, fast
    "gemini-1.5-pro",        # More capable
    "gemini-2.0-flash-exp",  # Experimental but good
]

MAX_FILE_SIZE = 20 * 1024 * 1024  # 20MB

# ============== SYSTEM PROMPTS ==============
PROMPTS = {
    "lecture": """You are a University Professor teaching in Persian (Farsi).
Listen to this audio carefully. Do NOT summarize.
Write a comprehensive **Textbook Chapter in Persian**.
Cover every single detail, example, and nuance mentioned.
Use bold headers (ÿ®ÿß ** ÿπŸÑÿßŸÖÿ™‚Äå⁄Øÿ∞ÿßÿ±€å ⁄©ŸÜ€åÿØ) to organize sections.
The goal is to replace the need to listen to the audio entirely.
Write in fluent, academic Persian. ÿ≤ÿ®ÿßŸÜ ÿÆÿ±Ÿàÿ¨€å ÿ≠ÿ™ŸÖÿßŸã ŸÅÿßÿ±ÿ≥€å ÿ®ÿßÿ¥ÿØ.""",

    "soap": """You are a Chief Resident at a teaching hospital.
Listen to this medical dictation audio.
Write a professional **SOAP Note in English**.
Format:
**Subjective:** (Chief complaint, HPI, ROS, PMH, medications, allergies)
**Objective:** (Vitals, physical exam findings, lab results, imaging)
**Assessment:** (Diagnoses with ICD codes if possible)
**Plan:** (Treatment plan, medications, follow-up)
Correct all medical terminology. Output MUST be in English only.""",

    "summary": """Listen to this audio carefully.
Summarize the content into clear, concise **Persian bullet points**.
Use ‚Ä¢ for bullet points. Write in fluent Persian.
Focus on the most important information.
ÿ≤ÿ®ÿßŸÜ ÿÆÿ±Ÿàÿ¨€å ÿ≠ÿ™ŸÖÿßŸã ŸÅÿßÿ±ÿ≥€å ÿ®ÿßÿ¥ÿØ.""",

    "lyrics": """Listen to this audio.
If it contains music: Extract and provide the complete lyrics in the original language.
If it contains speech: Provide a verbatim transcription in the original language.
Format the output cleanly with proper line breaks."""
}

# Persian messages
MESSAGES = {
    "welcome": """üéß **ÿ®Ÿá Omni-Hear AI ÿÆŸàÿ¥ ÿ¢ŸÖÿØ€åÿØ!**

üé§ €å⁄© ŸÅÿß€åŸÑ ÿµŸàÿ™€å €åÿß Ÿà€åÿ≥ ÿßÿ±ÿ≥ÿßŸÑ ⁄©ŸÜ€åÿØ.

‚ö° ŸÇÿßÿ®ŸÑ€åÿ™‚ÄåŸáÿß:
‚Ä¢ üìö ÿØÿ±ÿ≥ŸÜÿßŸÖŸá ⁄©ÿßŸÖŸÑ (ŸÅÿßÿ±ÿ≥€å)
‚Ä¢ ü©∫ ÿ¥ÿ±ÿ≠‚Äåÿ≠ÿßŸÑ Ÿæÿ≤ÿ¥⁄©€å SOAP (ÿßŸÜ⁄ØŸÑ€åÿ≥€å)
‚Ä¢ üìù ÿÆŸÑÿßÿµŸá ŸÖÿ™ŸÜ (ŸÅÿßÿ±ÿ≥€å)
‚Ä¢ üéµ ŸÖÿ™ŸÜ ÿ¢ŸáŸÜ⁄Ø

üîÑ ŸÜÿ≥ÿÆŸá 2.3 - Ÿæÿß€åÿØÿßÿ± Ÿà ÿ≥ÿ±€åÿπ""",
    "audio_received": "üéµ ŸÅÿß€åŸÑ ÿØÿ±€åÿßŸÅÿ™ ÿ¥ÿØ!\n\nüìã ŸÜŸàÿπ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ±ÿß ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ:",
    "processing": "‚è≥ ÿØÿ± ÿ≠ÿßŸÑ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ®ÿß ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å...\n\n‚è± ŸÑÿ∑ŸÅÿßŸã ÿµÿ®ÿ± ⁄©ŸÜ€åÿØ (€±€∞-€≥€∞ ÿ´ÿßŸÜ€åŸá)",
    "error": "‚ùå ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥. ŸÑÿ∑ŸÅÿßŸã ÿØŸàÿ®ÿßÿ±Ÿá ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ.",
    "error_detail": "‚ùå ÿÆÿ∑ÿß: {error}\n\nŸÑÿ∑ŸÅÿßŸã ÿØŸàÿ®ÿßÿ±Ÿá ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ.",
    "all_failed": "‚ùå ÿ™ŸÖÿßŸÖ ŸÖÿØŸÑ‚ÄåŸáÿß ÿ®ÿß ÿÆÿ∑ÿß ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØŸÜÿØ.\n\nüîç ÿ¨ÿ≤ÿ¶€åÿßÿ™: {details}\n\nŸÑÿ∑ŸÅÿßŸã ÿ®ÿπÿØÿßŸã ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ.",
    "no_audio": "‚ö†Ô∏è ŸÑÿ∑ŸÅÿßŸã ÿßÿ®ÿ™ÿØÿß €å⁄© ŸÅÿß€åŸÑ ÿµŸàÿ™€å ÿßÿ±ÿ≥ÿßŸÑ ⁄©ŸÜ€åÿØ.",
    "file_too_large": "‚ö†Ô∏è ÿ≠ÿ¨ŸÖ ŸÅÿß€åŸÑ ÿ®€åÿ¥ÿ™ÿ± ÿßÿ≤ €≤€∞ ŸÖ⁄Øÿßÿ®ÿß€åÿ™ ÿßÿ≥ÿ™.",
    "not_audio": "‚ö†Ô∏è ŸÑÿ∑ŸÅÿßŸã €å⁄© ŸÅÿß€åŸÑ ÿµŸàÿ™€å ÿßÿ±ÿ≥ÿßŸÑ ⁄©ŸÜ€åÿØ.",
    "api_key_missing": "‚ö†Ô∏è ÿ™ŸÜÿ∏€åŸÖÿßÿ™ ÿ≥ÿ±Ÿàÿ± ŸÜÿßŸÇÿµ ÿßÿ≥ÿ™. ŸÑÿ∑ŸÅÿßŸã ÿ®ÿß ÿßÿØŸÖ€åŸÜ ÿ™ŸÖÿßÿ≥ ÿ®⁄Ø€åÿ±€åÿØ.",
}

# Store user audio files temporarily
user_audio_cache: dict = {}


def get_menu_keyboard() -> InlineKeyboardMarkup:
    """Create the Persian inline keyboard menu."""
    return InlineKeyboardMarkup([
        [
            InlineKeyboardButton("üìö ÿØÿ±ÿ≥ŸÜÿßŸÖŸá ⁄©ÿßŸÖŸÑ", callback_data="lecture"),
            InlineKeyboardButton("ü©∫ ÿ¥ÿ±ÿ≠‚Äåÿ≠ÿßŸÑ Ÿæÿ≤ÿ¥⁄©€å", callback_data="soap"),
        ],
        [
            InlineKeyboardButton("üìù ÿÆŸÑÿßÿµŸá ŸÖÿ™ŸÜ", callback_data="summary"),
            InlineKeyboardButton("üéµ ŸÖÿ™ŸÜ ÿ¢ŸáŸÜ⁄Ø", callback_data="lyrics"),
        ],
    ])


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle the /start command."""
    await update.message.reply_text(MESSAGES["welcome"], parse_mode="Markdown")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle the /help command."""
    help_text = """üìñ **ÿ±ÿßŸáŸÜŸÖÿß€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá**

1Ô∏è‚É£ €å⁄© ŸÅÿß€åŸÑ ÿµŸàÿ™€å €åÿß Ÿà€åÿ≥ ÿßÿ±ÿ≥ÿßŸÑ ⁄©ŸÜ€åÿØ
2Ô∏è‚É£ ÿßÿ≤ ŸÖŸÜŸà ŸÜŸàÿπ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ±ÿß ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ
3Ô∏è‚É£ ŸÖŸÜÿ™ÿ∏ÿ± ŸÜÿ™€åÿ¨Ÿá ÿ®ŸÖÿßŸÜ€åÿØ (€±€∞-€≥€∞ ÿ´ÿßŸÜ€åŸá)

**ÿ≠ÿßŸÑÿ™‚ÄåŸáÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥:**
üìö **ÿØÿ±ÿ≥ŸÜÿßŸÖŸá ⁄©ÿßŸÖŸÑ** - ŸÖÿ™ŸÜ ÿØÿ±ÿ≥€å ⁄©ÿßŸÖŸÑ ÿ®Ÿá ŸÅÿßÿ±ÿ≥€å
ü©∫ **ÿ¥ÿ±ÿ≠‚Äåÿ≠ÿßŸÑ Ÿæÿ≤ÿ¥⁄©€å** - SOAP Note ÿ®Ÿá ÿßŸÜ⁄ØŸÑ€åÿ≥€å
üìù **ÿÆŸÑÿßÿµŸá ŸÖÿ™ŸÜ** - ÿÆŸÑÿßÿµŸá ŸÜ⁄©ÿßÿ™ ÿ®Ÿá ŸÅÿßÿ±ÿ≥€å
üéµ **ŸÖÿ™ŸÜ ÿ¢ŸáŸÜ⁄Ø** - ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ŸÖÿ™ŸÜ/ŸÑ€åÿ±€å⁄©

üí° ÿ≠ÿØÿß⁄©ÿ´ÿ± ÿ≠ÿ¨ŸÖ: €≤€∞ ŸÖ⁄Øÿßÿ®ÿß€åÿ™
ü§ñ ŸÖÿØŸÑ: Gemini 1.5"""
    await update.message.reply_text(help_text, parse_mode="Markdown")


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Check bot status and API connectivity."""
    status_parts = ["üîç **Ÿàÿ∂ÿπ€åÿ™ ÿ≥€åÿ≥ÿ™ŸÖ:**\n"]
    
    # Check Telegram Token
    if TELEGRAM_BOT_TOKEN:
        status_parts.append("‚úÖ Telegram Token: ÿ™ŸÜÿ∏€åŸÖ ÿ¥ÿØŸá")
    else:
        status_parts.append("‚ùå Telegram Token: ÿ™ŸÜÿ∏€åŸÖ ŸÜÿ¥ÿØŸá!")
    
    # Check Gemini API Key
    if GEMINI_API_KEY:
        status_parts.append(f"‚úÖ Gemini API Key: {GEMINI_API_KEY[:8]}...")
        
        # Test Gemini connection
        try:
            model = genai.GenerativeModel("gemini-1.5-flash")
            response = model.generate_content("Say 'OK' in one word.")
            status_parts.append("‚úÖ Gemini API: ŸÖÿ™ÿµŸÑ Ÿà ŸÅÿπÿßŸÑ")
        except Exception as e:
            status_parts.append(f"‚ùå Gemini API Error: {str(e)[:50]}")
    else:
        status_parts.append("‚ùå Gemini API Key: ÿ™ŸÜÿ∏€åŸÖ ŸÜÿ¥ÿØŸá!")
    
    status_parts.append(f"\nüîÑ ŸÖÿØŸÑ‚ÄåŸáÿß: {', '.join(MODEL_PRIORITY)}")
    
    await update.message.reply_text("\n".join(status_parts), parse_mode="Markdown")


async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle incoming audio files and voice messages."""
    user_id = update.effective_user.id
    msg = update.message
    
    # Check API Key first
    if not GEMINI_API_KEY:
        await msg.reply_text(MESSAGES["api_key_missing"])
        return
    
    audio_file = None
    file_type = "audio"
    
    if msg.voice:
        audio_file = msg.voice
        file_type = "voice"
    elif msg.audio:
        audio_file = msg.audio
    elif msg.document:
        if msg.document.mime_type and msg.document.mime_type.startswith("audio/"):
            audio_file = msg.document
        else:
            await msg.reply_text(MESSAGES["not_audio"])
            return
    else:
        await msg.reply_text(MESSAGES["not_audio"])
        return
    
    # File size check
    file_size = getattr(audio_file, 'file_size', 0)
    if file_size and file_size > MAX_FILE_SIZE:
        logger.warning(f"User {user_id}: file too large ({file_size} bytes)")
        await msg.reply_text(MESSAGES["file_too_large"])
        return
    
    try:
        file = await context.bot.get_file(audio_file.file_id)
        
        if file.file_size and file.file_size > MAX_FILE_SIZE:
            await msg.reply_text(MESSAGES["file_too_large"])
            return
        
        audio_bytes = await file.download_as_bytearray()
        
        # Determine mime type
        if file_type == "voice":
            mime_type = "audio/ogg"
        elif hasattr(audio_file, 'mime_type') and audio_file.mime_type:
            mime_type = audio_file.mime_type
        else:
            mime_type = "audio/mpeg"
        
        # Cache audio
        user_audio_cache[user_id] = {
            "data": bytes(audio_bytes),
            "mime_type": mime_type
        }
        
        logger.info(f"‚úÖ Audio cached: user={user_id}, size={len(audio_bytes)}, mime={mime_type}")
        await msg.reply_text(MESSAGES["audio_received"], reply_markup=get_menu_keyboard())
        
    except Exception as e:
        logger.error(f"Error downloading audio for user {user_id}: {e}")
        await msg.reply_text(MESSAGES["error"])


async def process_with_cascade(
    audio_data: bytes,
    mime_type: str,
    mode: str
) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """
    Process audio with model cascade.
    Returns: (result_text, model_used, error_message)
    """
    audio_b64 = base64.standard_b64encode(audio_data).decode("utf-8")
    last_error = None
    
    for i, model_name in enumerate(MODEL_PRIORITY):
        try:
            logger.info(f"üîÑ Trying model {i+1}/{len(MODEL_PRIORITY)}: {model_name}")
            
            model = genai.GenerativeModel(model_name)
            
            # Create content with audio
            response = await asyncio.to_thread(
                model.generate_content,
                [
                    {"inline_data": {"mime_type": mime_type, "data": audio_b64}},
                    PROMPTS.get(mode, PROMPTS["summary"])
                ],
                generation_config={
                    "temperature": 0.7,
                    "max_output_tokens": 8192
                }
            )
            
            if response.text:
                logger.info(f"‚úÖ Success with: {model_name}")
                return response.text, model_name, None
            else:
                logger.warning(f"‚ö†Ô∏è Empty response from {model_name}")
                last_error = "Empty response"
                continue
                
        except google_exceptions.InvalidArgument as e:
            error_msg = str(e)
            logger.warning(f"‚ùå {model_name} - Invalid argument: {error_msg[:100]}")
            last_error = f"Model doesn't support audio: {error_msg[:50]}"
            continue
            
        except google_exceptions.NotFound as e:
            logger.warning(f"‚ùå {model_name} - Model not found: {e}")
            last_error = f"Model not found: {model_name}"
            continue
            
        except google_exceptions.ResourceExhausted as e:
            logger.warning(f"‚ùå {model_name} - Quota exhausted: {e}")
            last_error = "API quota exhausted"
            continue
            
        except google_exceptions.PermissionDenied as e:
            logger.error(f"‚ùå {model_name} - Permission denied: {e}")
            last_error = "Invalid API key or no access"
            continue
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"‚ùå {model_name} - Unexpected error: {error_msg}")
            logger.error(traceback.format_exc())
            last_error = error_msg[:100]
            continue
    
    logger.error(f"‚ùå All models failed! Last error: {last_error}")
    return None, None, last_error


async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle button callbacks."""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    mode = query.data
    
    if user_id not in user_audio_cache:
        await query.edit_message_text(MESSAGES["no_audio"])
        return
    
    try:
        audio_info = user_audio_cache[user_id]
        
        mode_names = {
            "lecture": "üìö ÿØÿ±ÿ≥ŸÜÿßŸÖŸá ⁄©ÿßŸÖŸÑ",
            "soap": "ü©∫ ÿ¥ÿ±ÿ≠‚Äåÿ≠ÿßŸÑ Ÿæÿ≤ÿ¥⁄©€å",
            "summary": "üìù ÿÆŸÑÿßÿµŸá ŸÖÿ™ŸÜ",
            "lyrics": "üéµ ŸÖÿ™ŸÜ ÿ¢ŸáŸÜ⁄Ø"
        }
        
        await query.edit_message_text(
            f"{MESSAGES['processing']}\n\nüéØ ÿ≠ÿßŸÑÿ™: {mode_names.get(mode, mode)}"
        )
        
        result, model_used, error = await process_with_cascade(
            audio_info["data"],
            audio_info["mime_type"],
            mode
        )
        
        if result:
            # Success
            full_text = f"‚úÖ **{mode_names.get(mode, 'Ÿæÿ±ÿØÿßÿ≤ÿ¥')} ⁄©ÿßŸÖŸÑ ÿ¥ÿØ**\n\n{result}\n\n---\nü§ñ `{model_used}`"
            
            # Handle long messages
            if len(full_text) > 4000:
                try:
                    await query.edit_message_text(full_text[:4000], parse_mode="Markdown")
                except Exception:
                    await query.edit_message_text(full_text[:4000])
                
                remaining = full_text[4000:]
                while remaining:
                    chunk = remaining[:4000]
                    remaining = remaining[4000:]
                    try:
                        await context.bot.send_message(
                            chat_id=update.effective_chat.id,
                            text=chunk,
                            parse_mode="Markdown"
                        )
                    except Exception:
                        await context.bot.send_message(
                            chat_id=update.effective_chat.id,
                            text=chunk
                        )
            else:
                try:
                    await query.edit_message_text(full_text, parse_mode="Markdown")
                except Exception:
                    await query.edit_message_text(full_text)
        else:
            # All models failed - show error details
            error_msg = MESSAGES["all_failed"].format(details=error or "Unknown error")
            await query.edit_message_text(error_msg)
    
    except Exception as e:
        logger.error(f"Callback error for user {user_id}: {e}")
        logger.error(traceback.format_exc())
        try:
            await query.edit_message_text(MESSAGES["error_detail"].format(error=str(e)[:100]))
        except Exception:
            pass
    
    finally:
        # Always cleanup cache
        if user_id in user_audio_cache:
            del user_audio_cache[user_id]
            logger.info(f"üßπ Cache cleaned: user={user_id}")


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle errors."""
    logger.error(f"Update {update} caused error: {context.error}")
    logger.error(traceback.format_exc())


def main() -> None:
    """Start the bot."""
    print("\n" + "="*50)
    print("üéß OMNI-HEAR AI v2.3")
    print("="*50)
    
    # Validate tokens
    if not TELEGRAM_BOT_TOKEN:
        logger.error("‚ùå TELEGRAM_BOT_TOKEN not set!")
        print("\n‚ö†Ô∏è  Set environment variables:")
        print("   TELEGRAM_BOT_TOKEN=your_bot_token")
        print("   GEMINI_API_KEY=your_gemini_key\n")
        sys.exit(1)
    
    if not GEMINI_API_KEY:
        logger.error("‚ùå GEMINI_API_KEY not set!")
        print("\n‚ö†Ô∏è  Get your API key from:")
        print("   https://aistudio.google.com/app/apikey\n")
        sys.exit(1)
    
    print(f"‚úÖ Telegram Token: {TELEGRAM_BOT_TOKEN[:10]}...")
    print(f"‚úÖ Gemini API Key: {GEMINI_API_KEY[:10]}...")
    print(f"üîÑ Models: {' ‚Üí '.join(MODEL_PRIORITY)}")
    print("="*50 + "\n")
    
    # Build application
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # Add handlers
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("status", status_command))
    app.add_handler(MessageHandler(
        filters.VOICE | filters.AUDIO | filters.Document.AUDIO,
        handle_audio
    ))
    app.add_handler(CallbackQueryHandler(button_callback))
    app.add_error_handler(error_handler)
    
    # Run
    logger.info("üöÄ Starting Omni-Hear AI v2.3...")
    app.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)


if __name__ == "__main__":
    main()
