#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   OMNI-HEAR AI v6.0 (Dual-Engine Edition)                    â•‘
â•‘            âš¡ Fast Mode (Groq 70B) | ğŸš€ Pro Mode (SambaNova 405B)            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ¤ STT: Groq Whisper Large V3 (with context prompting)                      â•‘
â•‘  âš¡ Fast LLM: Groq Llama 3.3 70B (~3 seconds)                                â•‘
â•‘  ğŸš€ Pro LLM: SambaNova Llama 3.1 405B (Maximum Accuracy)                     â•‘
â•‘  ğŸŒ 7 Languages | ğŸ”„ Auto-Fallback | ğŸ“Š Dual-Button UI                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import logging
import asyncio
import tempfile
import traceback
from typing import Optional, Dict, Tuple
from dataclasses import dataclass
from enum import Enum

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

from groq import Groq
from openai import OpenAI
from pydub import AudioSegment

# ============== LOGGING ==============
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ============== CONFIGURATION ==============
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
SAMBANOVA_API_KEY = os.getenv("SAMBANOVA_API_KEY")

# ============== API CLIENTS ==============
groq_client: Optional[Groq] = None
sambanova_client: Optional[OpenAI] = None

if GROQ_API_KEY:
    groq_client = Groq(api_key=GROQ_API_KEY)
    logger.info("âœ… Groq client initialized")
else:
    logger.error("âŒ GROQ_API_KEY not set!")

if SAMBANOVA_API_KEY:
    sambanova_client = OpenAI(
        api_key=SAMBANOVA_API_KEY,
        base_url="https://api.sambanova.ai/v1"
    )
    logger.info("âœ… SambaNova client initialized")
else:
    logger.warning("âš ï¸ SAMBANOVA_API_KEY not set - Pro mode unavailable")

# ============== MODEL CONFIGURATION ==============
WHISPER_MODEL = "whisper-large-v3"
GROQ_LLM_PRIMARY = "llama-3.3-70b-versatile"
GROQ_LLM_FALLBACK = "llama-3.1-8b-instant"
SAMBANOVA_MODEL_PRO = "Meta-Llama-3.1-405B-Instruct"
SAMBANOVA_MODEL_FALLBACK = "Meta-Llama-3.1-70B-Instruct"

MAX_FILE_SIZE = 25 * 1024 * 1024  # 25MB

# Whisper context prompt for better accuracy
WHISPER_CONTEXT_PROMPT = """Medical terminology: SOAP, diagnosis, patient, symptoms, treatment, prescription, 
blood pressure, cardiac, respiratory, neurological, assessment, differential diagnosis.
Academic terms: professor, lecture, university, chapter, introduction, conclusion, methodology.
Persian academic: Ø¯Ø±Ø³ØŒ Ø§Ø³ØªØ§Ø¯ØŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ØŒ ÙØµÙ„ØŒ Ù…Ù‚Ø¯Ù…Ù‡ØŒ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒØŒ ØªØ´Ø®ÛŒØµØŒ Ø¨ÛŒÙ…Ø§Ø±ØŒ Ø¯Ø±Ù…Ø§Ù†."""


# ============== ENGINE TYPES ==============
class Engine(Enum):
    FAST = "fast"   # Groq 70B
    PRO = "pro"     # SambaNova 405B


# ============== LANGUAGES ==============
@dataclass
class Language:
    code: str
    name_en: str
    name_native: str
    flag: str


LANGUAGES: Dict[str, Language] = {
    "fa": Language("fa", "Persian", "ÙØ§Ø±Ø³ÛŒ", "ğŸ‡®ğŸ‡·"),
    "en": Language("en", "English", "English", "ğŸ‡¬ğŸ‡§"),
    "fr": Language("fr", "French", "FranÃ§ais", "ğŸ‡«ğŸ‡·"),
    "es": Language("es", "Spanish", "EspaÃ±ol", "ğŸ‡ªğŸ‡¸"),
    "ru": Language("ru", "Russian", "Ğ ÑƒÑÑĞºĞ¸Ğ¹", "ğŸ‡·ğŸ‡º"),
    "de": Language("de", "German", "Deutsch", "ğŸ‡©ğŸ‡ª"),
    "ar": Language("ar", "Arabic", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "ğŸ‡¸ğŸ‡¦"),
}

# ============== USER STATE ==============
user_audio_cache: Dict[int, dict] = {}
user_state: Dict[int, dict] = {}


# ============== ADVANCED SYSTEM PROMPTS ==============

def get_soap_prompt_pro() -> str:
    """Advanced Medical SOAP prompt for 405B Pro Engine."""
    return """Role: Senior Board-Certified Attending Physician with 20+ years of clinical experience at a major academic medical center.

Task: Transform the provided medical dictation into a comprehensive, US Medical Standard clinical SOAP Note that meets Joint Commission (JCAHO) documentation requirements.

DOCUMENTATION STANDARDS:
- Follow CMS Documentation Guidelines
- Include all medically necessary information
- Use standard medical abbreviations appropriately
- Maintain HIPAA-compliant language

FORMAT:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         SOAP NOTE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ SUBJECTIVE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Chief Complaint (CC):**
[Primary reason for visit - patient's own words in quotes]

**History of Present Illness (HPI):**
Capture with chronological precision using OLDCARTS:
- Onset: [When did it start?]
- Location: [Where is the problem?]
- Duration: [How long does it last?]
- Character: [What does it feel like?]
- Aggravating Factors: [What makes it worse?]
- Relieving Factors: [What makes it better?]
- Timing: [When does it occur?]
- Severity: [Rate 1-10]
- Associated Symptoms: [Related symptoms]

**Review of Systems (ROS):**
â–¡ Constitutional: [Fever, weight changes, fatigue]
â–¡ HEENT: [Head, eyes, ears, nose, throat]
â–¡ Cardiovascular: [Chest pain, palpitations, edema]
â–¡ Respiratory: [Dyspnea, cough, wheezing]
â–¡ Gastrointestinal: [Nausea, vomiting, abdominal pain]
â–¡ Genitourinary: [Dysuria, frequency, hematuria]
â–¡ Musculoskeletal: [Joint pain, stiffness, swelling]
â–¡ Neurological: [Headache, dizziness, weakness]
â–¡ Psychiatric: [Mood, anxiety, sleep]
â–¡ Integumentary: [Rash, lesions, changes]

**Past Medical History (PMH):**
**Past Surgical History (PSH):**
**Medications:** [Include dose, frequency, route]
**Allergies:** [Drug allergies with reaction type - NKDA if none]
**Family History (FHx):**
**Social History (SHx):**
- Tobacco: [Pack-years or never]
- Alcohol: [Drinks per week]
- Illicit drugs: [Yes/No, type if yes]
- Occupation:
- Living situation:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”¬ OBJECTIVE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Vital Signs:**
| Parameter | Value | Reference |
|-----------|-------|-----------|
| BP | /mmHg | <120/80 |
| HR | bpm | 60-100 |
| RR | /min | 12-20 |
| Temp | Â°F (Â°C) | 97.8-99.1Â°F |
| SpO2 | % | >95% |
| Weight | kg/lbs | |
| Height | cm/in | |
| BMI | kg/mÂ² | 18.5-24.9 |

**Physical Examination:**

*General:* [Appearance, distress level, cooperation]

*HEENT:*
- Head: [Normocephalic, atraumatic]
- Eyes: [PERRLA, EOM intact, conjunctivae]
- Ears: [TMs, canals]
- Nose: [Patency, mucosa]
- Throat: [Oropharynx, tonsils, uvula]

*Neck:* [Supple, lymphadenopathy, thyroid, JVD]

*Cardiovascular:* [Rate, rhythm, murmurs, S1/S2, peripheral pulses, edema]

*Pulmonary:* [Effort, breath sounds, wheezes, rhonchi, rales]

*Abdomen:* [Soft, tenderness, distension, bowel sounds, organomegaly]

*Extremities:* [Edema, cyanosis, clubbing, ROM]

*Neurological:* [Mental status, cranial nerves, motor, sensory, reflexes, gait]

*Skin:* [Color, turgor, lesions, rashes]

**Diagnostic Results:**

*Laboratory:*
| Test | Result | Reference Range | Flag |
|------|--------|-----------------|------|
| | | | |

*Imaging:*
[Modality, findings, impression]

*Other Studies:*
[EKG, PFTs, etc.]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ ASSESSMENT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Primary Diagnosis:**
[Diagnosis] â€” ICD-10: [Code]

**Differential Diagnoses (Prioritized):**
1. [Most likely] â€” ICD-10: [Code]
   - Supporting evidence:
   - Against:
2. [Second likely] â€” ICD-10: [Code]
3. [Third likely] â€” ICD-10: [Code]

**Clinical Reasoning:**
[Brief explanation of diagnostic thought process]

**Risk Stratification:**
[Low/Moderate/High risk with justification]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ PLAN
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Diagnostic Plan:**
- [ ] [Tests to order with rationale]

**Therapeutic Plan:**
- [ ] [Medications: Drug, Dose, Route, Frequency, Duration]
- [ ] [Procedures]
- [ ] [Therapies]

**Patient Education:**
- [ ] [Key points discussed]
- [ ] [Warning signs to watch for]
- [ ] [Lifestyle modifications]

**Disposition:**
â˜ Discharge home
â˜ Admit to: [Unit]
â˜ Transfer to: [Facility]
â˜ Observation

**Follow-up:**
- [Timeframe]: [Provider/Specialty]
- Return precautions: [Specific symptoms]

**Referrals:**
- [ ] [Specialty]: [Reason]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CRITICAL INSTRUCTIONS:
1. OUTPUT MUST BE IN ENGLISH ONLY
2. Correct any medical mispronunciations from transcription
3. Use standard medical terminology and abbreviations
4. Include ICD-10 codes for all diagnoses
5. If information not provided, mark as "Not documented" or "Not assessed"
6. Flag any critical or concerning findings with âš ï¸
7. Maintain formal, objective clinical tone throughout"""


def get_soap_prompt_fast() -> str:
    """Simplified SOAP prompt for Fast Engine."""
    return """You are an experienced physician. Create a SOAP Note from this medical dictation.

FORMAT:
## SUBJECTIVE
- CC, HPI, ROS, PMH, Medications, Allergies

## OBJECTIVE  
- Vitals, Physical Exam, Labs/Imaging

## ASSESSMENT
- Diagnosis with ICD-10 codes
- Differential diagnoses

## PLAN
- Treatment, medications, follow-up

OUTPUT: English only. Correct medical terminology errors."""


def get_lecture_prompt_pro(lang: str = "fa") -> str:
    """Advanced Academic Lecture prompt for 405B Pro Engine."""
    prompts = {
        "fa": """Ù†Ù‚Ø´: Ø§Ø³ØªØ§Ø¯ Ø¨Ø±Ø¬Ø³ØªÙ‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¨Ø§ Ø³Ø§Ø¨Ù‚Ù‡ Û²Û° Ø³Ø§Ù„Ù‡ ØªØ¯Ø±ÛŒØ³ Ùˆ ØªØ£Ù„ÛŒÙ Ú©ØªØ¨ Ù…Ø±Ø¬Ø¹ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ.

ÙˆØ¸ÛŒÙÙ‡: ØªØ¨Ø¯ÛŒÙ„ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ ØµÙˆØª Ø¨Ù‡ ÛŒÚ© ÙØµÙ„ Ø¬Ø§Ù…Ø¹ Ú©ØªØ§Ø¨ Ù…Ø±Ø¬Ø¹ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ (Ø¯Ø± Ø³Ø·Ø­ Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¬Ø¹ Ù…Ø§Ù†Ù†Ø¯ Ù‡Ø§Ø±ÛŒØ³ÙˆÙ†ØŒ Ú¯Ø§ÛŒØªÙˆÙ†ØŒ ÛŒØ§ Ø±Ø§Ø¨ÛŒÙ†Ø²).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      ÙØµÙ„ Ø¯Ø±Ø³ÛŒ Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š Ø³Ø§Ø®ØªØ§Ø± Ø§Ù„Ø²Ø§Ù…ÛŒ:

**Û±. Ù…Ù‚Ø¯Ù…Ù‡ Ø¹Ù„Ù…ÛŒ (Introduction)**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- ØªØ¹Ø±ÛŒÙ Ø¯Ù‚ÛŒÙ‚ Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø§ Ø§Ø±Ø¬Ø§Ø¹ Ø¨Ù‡ Ù…ÙØ§Ù‡ÛŒÙ… Ù¾Ø§ÛŒÙ‡
- Ø§Ù‡Ù…ÛŒØª Ø¨Ø§Ù„ÛŒÙ†ÛŒ/Ø¹Ù„Ù…ÛŒ Ù…ÙˆØ¶ÙˆØ¹
- Ø§Ù‡Ø¯Ø§Ù ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§ÛŒÙ† ÙØµÙ„
- Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ù‡

**Û². Ù…ØªÙ† Ø§ØµÙ„ÛŒ (Main Content)**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø§ **Ø¹Ù†Ø§ÙˆÛŒÙ† Ø¯Ø±Ø´Øª**
- ØªÙˆØ¶ÛŒØ­ Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… Ù…ÙØ§Ù‡ÛŒÙ… Ø§Ø² Ø³Ø§Ø¯Ù‡ Ø¨Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„ÛŒÙ†ÛŒ/Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ
- Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÛŒÙ† Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ø®ØªÙ„Ù

**Û³. Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ (Clinical Pearls) ğŸ’**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Ù†Ú©Ø§Øª Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ Ø¨Ù‡â€ŒØ®Ø§Ø·Ø± Ø³Ù¾Ø±Ø¯Ù†
- Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø±Ø§ÛŒØ¬ Ùˆ Ù†Ø­ÙˆÙ‡ Ø§Ø¬ØªÙ†Ø§Ø¨
- Ù†Ú©Ø§Øª Ø§Ù…ØªØ­Ø§Ù†ÛŒ (High-Yield Points)

**Û´. Ø¬Ø¯Ø§ÙˆÙ„ Ø¢Ù…ÙˆØ²Ø´ÛŒ (Educational Tables) ğŸ“Š**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
| Ø¹Ù†ÙˆØ§Ù† | ØªÙˆØ¶ÛŒØ­ | Ù…Ø«Ø§Ù„ |
|-------|-------|------|
| | | |

**Ûµ. Ø®Ù„Ø§ØµÙ‡ ÙØµÙ„ (Summary)**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Ù…Ø±ÙˆØ± Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
- Ù†Ù‚Ø´Ù‡ Ù…ÙÙ‡ÙˆÙ…ÛŒ (Concept Map)

**Û¶. Ø³Ø¤Ø§Ù„Ø§Øª Ù…Ø±ÙˆØ±ÛŒ (Review Questions)**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Û³-Ûµ Ø³Ø¤Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ¯Ø¢Ø²Ù…Ø§ÛŒÛŒ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Ø§Ù„Ø²Ø§Ù…Ø§Øª Ù†Ú¯Ø§Ø±Ø´ÛŒ:

Û±. **Ø²Ø¨Ø§Ù†:** ÙØ§Ø±Ø³ÛŒ Ø±Ø³Ù…ÛŒ Ùˆ Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ© - Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø¹Ø§Ù…ÛŒØ§Ù†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø´ÙˆØ¯
Û². **Ø§ØµØ·Ù„Ø§Ø­Ø§Øª ØªØ®ØµØµÛŒ:** Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ù…Ø¹Ø§Ø¯Ù„ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¯Ø± Ù¾Ø±Ø§Ù†ØªØ²
   Ù…Ø«Ø§Ù„: ÙØ´Ø§Ø± Ø®ÙˆÙ† (Blood Pressure)
Û³. **Ø³Ø§Ø®ØªØ§Ø± Ø¬Ù…Ù„Ø§Øª:** Ø±ÙˆØ§Ù†ØŒ Ø¹Ù„Ù…ÛŒØŒ Ø¨Ø¯ÙˆÙ† Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ
Û´. **Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒØ¨Ù†Ø¯ÛŒ:** Ù‡Ø± Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù ÛŒÚ© Ø§ÛŒØ¯Ù‡ Ø§ØµÙ„ÛŒ
Ûµ. **ØªØ£Ú©ÛŒØ¯:** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **Ø¨ÙˆÙ„Ø¯** Ø¨Ø±Ø§ÛŒ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

ğŸ¯ Ù‡Ø¯Ù Ù†Ù‡Ø§ÛŒÛŒ: Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ Ù¾Ø³ Ø§Ø² Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø§ÛŒÙ† ÙØµÙ„ØŒ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ ØµÙˆØª Ø§ØµÙ„ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ø¯Ø±Ú© Ú©Ø§Ù…Ù„ÛŒ Ø§Ø² Ù…ÙˆØ¶ÙˆØ¹ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ø¯.

Ø²Ø¨Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ: ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ©""",

        "en": """Role: Distinguished University Professor with 20+ years of teaching and textbook authoring experience.

Task: Transform the audio transcription into a comprehensive Reference Textbook Chapter (similar to Harrison's, Guyton's, or Robbins' standards).

STRUCTURE:

## 1. Introduction
- Scientific definition with foundational concepts
- Clinical/scientific significance
- Learning objectives
- Prerequisites

## 2. Main Content
- Logical organization with **bold headers**
- Step-by-step explanation from simple to complex
- Clinical/practical examples
- Concept interconnections

## 3. Clinical Pearls ğŸ’
- Key points to remember
- Common mistakes to avoid
- High-yield examination points

## 4. Educational Tables ğŸ“Š
| Topic | Description | Example |
|-------|-------------|---------|

## 5. Chapter Summary
- Key points review
- Concept map

## 6. Review Questions
- 3-5 self-assessment questions

OUTPUT LANGUAGE: English only, formal academic tone.""",

        "fr": """RÃ´le: Professeur d'universitÃ© distinguÃ©.
TÃ¢che: Transformer la transcription en un chapitre de manuel acadÃ©mique complet en franÃ§ais.
Structure: Introduction, Contenu principal avec en-tÃªtes, Points clÃ©s, Tableaux, RÃ©sumÃ©, Questions.
LANGUE DE SORTIE: FranÃ§ais acadÃ©mique uniquement.""",

        "es": """Rol: Profesor universitario distinguido.
Tarea: Transformar la transcripciÃ³n en un capÃ­tulo de libro de texto acadÃ©mico completo en espaÃ±ol.
Estructura: IntroducciÃ³n, Contenido principal con encabezados, Puntos clave, Tablas, Resumen, Preguntas.
IDIOMA DE SALIDA: EspaÃ±ol acadÃ©mico Ãºnicamente.""",

        "de": """Rolle: Angesehener UniversitÃ¤tsprofessor.
Aufgabe: Die Transkription in ein umfassendes akademisches Lehrbuchkapitel auf Deutsch umwandeln.
Struktur: Einleitung, Hauptinhalt mit Ãœberschriften, Kernpunkte, Tabellen, Zusammenfassung, Fragen.
AUSGABESPRACHE: Nur akademisches Deutsch.""",

        "ru": """Ğ Ğ¾Ğ»ÑŒ: Ğ’Ñ‹Ğ´Ğ°ÑÑ‰Ğ¸Ğ¹ÑÑ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¾Ñ€ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚Ğ°.
Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ² Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½ÑƒÑ Ğ³Ğ»Ğ°Ğ²Ñƒ Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑƒÑ‡ĞµĞ±Ğ½Ğ¸ĞºĞ° Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.
Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°: Ğ’Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ, ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼Ğ¸, ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñ‹, Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹, Ğ ĞµĞ·ÑĞ¼Ğµ, Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹.
Ğ¯Ğ—Ğ«Ğš Ğ’Ğ«Ğ’ĞĞ”Ğ: Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹.""",

        "ar": """Ø§Ù„Ø¯ÙˆØ±: Ø£Ø³ØªØ§Ø° Ø¬Ø§Ù…Ø¹ÙŠ Ù…ØªÙ…ÙŠØ².
Ø§Ù„Ù…Ù‡Ù…Ø©: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªÙˆØ¨ Ø¥Ù„Ù‰ ÙØµÙ„ ÙƒØªØ§Ø¨ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø´Ø§Ù…Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
Ø§Ù„Ù‡ÙŠÙƒÙ„: Ù…Ù‚Ø¯Ù…Ø©ØŒ Ù…Ø­ØªÙˆÙ‰ Ø±Ø¦ÙŠØ³ÙŠ Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ†ØŒ Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©ØŒ Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ù…Ù„Ø®ØµØŒ Ø£Ø³Ø¦Ù„Ø©.
Ù„ØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© ÙÙ‚Ø·."""
    }
    return prompts.get(lang, prompts["en"])


def get_lecture_prompt_fast(lang: str = "fa") -> str:
    """Simplified Lecture prompt for Fast Engine."""
    target = LANGUAGES.get(lang, LANGUAGES["fa"])
    return f"""You are a university professor. Create a comprehensive lecture notes document.

Include:
1. Introduction
2. Main content with bold headers
3. Key points
4. Summary

OUTPUT LANGUAGE: {target.name_en} ({target.name_native}) only."""


def get_summary_prompt(lang: str, engine: Engine) -> str:
    """Summary prompt for specified language and engine."""
    target = LANGUAGES.get(lang, LANGUAGES["fa"])
    
    if engine == Engine.PRO:
        return f"""Role: Expert Content Analyst and Academic Summarizer.

Task: Create a comprehensive, structured summary in {target.name_en} ({target.name_native}).

FORMAT:

ğŸ“Œ **Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ / Executive Summary**
[3-4 sentences capturing the essence]

ğŸ“‹ **Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ / Key Points**
â€¢ [Point 1 - most important]
â€¢ [Point 2]
â€¢ [Point 3]
â€¢ [Continue as needed...]

ğŸ’¡ **Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ù‡Ù… / Critical Details**
[Names, numbers, dates, specific information]

ğŸ“Š **Ø³Ø§Ø®ØªØ§Ø± Ù…Ø­ØªÙˆØ§ / Content Structure**
[How the original content was organized]

ğŸ¯ **Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ / Conclusions**
[Main takeaways and implications]

âœ… **Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ / Recommended Actions** (if applicable)
[Any action items mentioned]

OUTPUT LANGUAGE: {target.name_en.upper()} ({target.name_native}) ONLY"""
    else:
        return f"""Summarize this content in {target.name_en}.

Include:
â€¢ Overview (2-3 sentences)
â€¢ Key points (bullet list)
â€¢ Conclusion

OUTPUT: {target.name_en} only."""


def get_transcript_prompt(lang: str, engine: Engine) -> str:
    """Transcript formatting prompt."""
    target = LANGUAGES.get(lang, LANGUAGES["fa"])
    
    if engine == Engine.PRO:
        return f"""Role: Professional Transcription Specialist.

Task: Format and clean the raw transcription with expert precision.

RULES:
1. Fix transcription errors while preserving original meaning
2. Add proper punctuation (. , ? ! : ; â€”)
3. Create logical paragraph breaks
4. Mark speakers as [Speaker 1], [Speaker 2] if multiple
5. Preserve mixed-language content:
   - Keep English words in Latin script within {target.name_en} text
   - Example: "Ù…Ù† ÛŒÚ© meeting Ø¯Ø§Ø´ØªÙ…" stays as-is
6. Mark unclear audio as [Ù†Ø§Ù…ÙÙ‡ÙˆÙ…] or [unclear]
7. Add timestamps for long content: [00:00]
8. Preserve technical terms, names, and numbers exactly

FORMAT:
Clean, professional paragraphs with proper formatting.

OUTPUT LANGUAGE: Preserve original language, format in {target.name_en}."""
    else:
        return f"""Clean and format this transcription.
- Fix errors, add punctuation
- Create paragraphs
- Mark unclear parts as [unclear]
- Keep original language
OUTPUT: Formatted text."""


def get_lyrics_prompt(engine: Engine) -> str:
    """Lyrics extraction prompt."""
    if engine == Engine.PRO:
        return """Role: Professional Music Transcriptionist and Lyrics Analyst.

Task: Extract and format lyrics OR speech transcription with expert precision.

FOR MUSIC:
ğŸµ **Song Information** (if identifiable)
- Title:
- Artist:
- Album:
- Genre:
- Language:

---

[Intro] (if applicable)

[Verse 1]
Line 1
Line 2
...

[Pre-Chorus]
...

[Chorus]
...

[Verse 2]
...

[Bridge]
...

[Outro]
...

---

ğŸ“ **Notes:**
- Describe the mood/tone
- Note any background vocals
- Identify instruments if notable

FOR SPEECH:
Format as clean paragraphs with speaker identification.

RULES:
1. Keep ORIGINAL language - never translate
2. Mark instrumental: [ğŸ¸ Guitar Solo], [ğŸ¹ Piano], [ğŸ¥ Drums]
3. Mark unclear lyrics: [...]
4. Note harmonies: (harmony) or [Background: ...]
5. Include ad-libs in parentheses

OUTPUT: Original language, professionally formatted."""
    else:
        return """Extract lyrics or transcribe speech.

Format:
[Verse 1]
Lines...

[Chorus]
Lines...

Keep original language. Mark unclear parts as [...].
OUTPUT: Formatted lyrics/transcription."""


def get_translation_prompt(source_lang: str, target_lang: str, engine: Engine) -> str:
    """Translation prompt between languages."""
    source = LANGUAGES.get(source_lang, LANGUAGES["en"])
    target = LANGUAGES.get(target_lang, LANGUAGES["fa"])
    
    if engine == Engine.PRO:
        return f"""Role: Expert Translator with native fluency in both {source.name_en} and {target.name_en}.

Task: Translate the content from {source.name_en} to {target.name_en} with professional quality.

TRANSLATION PRINCIPLES:

1. **Semantic Accuracy:** Preserve complete meaning
2. **Natural Fluency:** Use idiomatic {target.name_en}
3. **Tone Preservation:** Maintain speaker's style
4. **Cultural Adaptation:** Adapt cultural references appropriately
5. **Technical Precision:** Keep specialized terms accurate

SPECIAL HANDLING:
- **Proper nouns:** Keep original or use standard transliteration
- **Idioms:** Use equivalent expressions, not literal translation
- **Numbers/Dates:** Convert to target locale if appropriate
- **Quotes:** Preserve with appropriate quotation marks
- **Technical terms:** Translate with original in parentheses

OUTPUT FORMAT:

ğŸ“ **{target.name_native} Translation:**

[Full translated text]

---

ğŸ“Œ **Ø®Ù„Ø§ØµÙ‡ / Summary:**
[2-3 sentence summary of content]

ğŸ”¤ **Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ / Keywords:**
[Key terms from the text]

OUTPUT LANGUAGE: {target.name_en.upper()} ({target.name_native}) ONLY"""
    else:
        return f"""Translate from {source.name_en} to {target.name_en}.

Maintain:
- Original meaning
- Natural expression
- Proper nouns

OUTPUT: {target.name_en} translation only."""


# ============== UI MESSAGES ==============
MESSAGES = {
    "welcome": """ğŸ§ **Ø¨Ù‡ Omni-Hear AI Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!**

ğŸš€ **Ù†Ø³Ø®Ù‡ 6.0 - Ù…ÙˆØªÙˆØ± Ø¯ÙˆÚ¯Ø§Ù†Ù‡**

**âš¡ Ø­Ø§Ù„Øª Ø³Ø±ÛŒØ¹:** Ù¾Ø§Ø³Ø® Ø¯Ø± Û³ Ø«Ø§Ù†ÛŒÙ‡ (Llama 70B)
**ğŸš€ Ø­Ø§Ù„Øª Ø¯Ù‚ÛŒÙ‚:** Ø­Ø¯Ø§Ú©Ø«Ø± Ú©ÛŒÙÛŒØª (Llama 405B)

ğŸ“¤ **ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÛŒØ§ ÙˆÛŒØ³ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯**

ğŸŒ **Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§:**
ğŸ‡®ğŸ‡· ÙØ§Ø±Ø³ÛŒ | ğŸ‡¬ğŸ‡§ English | ğŸ‡«ğŸ‡· FranÃ§ais
ğŸ‡ªğŸ‡¸ EspaÃ±ol | ğŸ‡©ğŸ‡ª Deutsch | ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©""",

    "audio_received": """ğŸµ **ÙØ§ÛŒÙ„ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯!** ({size})

âš¡ **Ø³Ø±ÛŒØ¹** = Ù¾Ø§Ø³Ø® Ø³Ø±ÛŒØ¹ (~Û³ Ø«Ø§Ù†ÛŒÙ‡)
ğŸš€ **Ø¯Ù‚ÛŒÙ‚** = Ú©ÛŒÙÛŒØª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ (405B)

ğŸ“‹ Ù†ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:""",

    "select_language": "ğŸŒ **Ø²Ø¨Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:**",
    "select_source_lang": "ğŸ—£ **Ø²Ø¨Ø§Ù† ØµÙˆØª (Ù…Ø¨Ø¯Ø§):**",
    "select_target_lang": "ğŸ¯ **Ø²Ø¨Ø§Ù† ØªØ±Ø¬Ù…Ù‡ (Ù…Ù‚ØµØ¯):**",
    
    "processing_stt": "ğŸ¤ **Ù…Ø±Ø­Ù„Ù‡ Û±/Û²:** ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†...",
    "processing_fast": "âš¡ **Ù…Ø±Ø­Ù„Ù‡ Û²/Û²:** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Llama 70B...",
    "processing_pro": "ğŸš€ **Ù…Ø±Ø­Ù„Ù‡ Û²/Û²:** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Llama 405B...",
    "fallback_notice": "âš ï¸ Ø³Ø±ÙˆÛŒØ³ 405B Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§Ù„Øª Ø³Ø±ÛŒØ¹...",
    
    "error": "âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
    "no_audio": "âš ï¸ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.",
    "file_too_large": "âš ï¸ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø² Û²Ûµ Ù…Ú¯Ø§Ø¨Ø§ÛŒØª Ø§Ø³Øª.",
    "not_audio": "âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ (MP3, OGG, WAV, M4A).",
    "api_missing": "âš ï¸ Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡: {missing}",
    "pro_unavailable": "âš ï¸ Ø­Ø§Ù„Øª Pro Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ø§Ø² Ø­Ø§Ù„Øª Ø³Ø±ÛŒØ¹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯.",
}


# ============== KEYBOARDS ==============
def get_main_menu_keyboard() -> InlineKeyboardMarkup:
    """Main menu with dual buttons for each feature."""
    return InlineKeyboardMarkup([
        # Transcript
        [
            InlineKeyboardButton("ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ âš¡", callback_data="mode:transcript:fast"),
            InlineKeyboardButton("ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ ğŸš€", callback_data="mode:transcript:pro"),
        ],
        # Lecture
        [
            InlineKeyboardButton("ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡ âš¡", callback_data="mode:lecture:fast"),
            InlineKeyboardButton("ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡ ğŸš€", callback_data="mode:lecture:pro"),
        ],
        # Medical SOAP
        [
            InlineKeyboardButton("ğŸ©º Ù¾Ø²Ø´Ú©ÛŒ âš¡", callback_data="mode:soap:fast"),
            InlineKeyboardButton("ğŸ©º Ù¾Ø²Ø´Ú©ÛŒ ğŸš€", callback_data="mode:soap:pro"),
        ],
        # Summary
        [
            InlineKeyboardButton("ğŸ“ Ø®Ù„Ø§ØµÙ‡ âš¡", callback_data="mode:summary:fast"),
            InlineKeyboardButton("ğŸ“ Ø®Ù„Ø§ØµÙ‡ ğŸš€", callback_data="mode:summary:pro"),
        ],
        # Lyrics
        [
            InlineKeyboardButton("ğŸµ Ù…ØªÙ† Ø¢Ù‡Ù†Ú¯ âš¡", callback_data="mode:lyrics:fast"),
            InlineKeyboardButton("ğŸµ Ù…ØªÙ† Ø¢Ù‡Ù†Ú¯ ğŸš€", callback_data="mode:lyrics:pro"),
        ],
        # Translation
        [
            InlineKeyboardButton("ğŸŒ ØªØ±Ø¬Ù…Ù‡ âš¡", callback_data="mode:translate:fast"),
            InlineKeyboardButton("ğŸŒ ØªØ±Ø¬Ù…Ù‡ ğŸš€", callback_data="mode:translate:pro"),
        ],
    ])


def get_language_keyboard(callback_prefix: str) -> InlineKeyboardMarkup:
    """Language selection keyboard."""
    buttons = []
    row = []
    
    for code, lang in LANGUAGES.items():
        btn = InlineKeyboardButton(
            f"{lang.flag} {lang.name_native}",
            callback_data=f"{callback_prefix}:{code}"
        )
        row.append(btn)
        if len(row) == 3:
            buttons.append(row)
            row = []
    
    if row:
        buttons.append(row)
    
    buttons.append([InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="back:main")])
    return InlineKeyboardMarkup(buttons)


def get_target_language_keyboard(source_lang: str, callback_prefix: str) -> InlineKeyboardMarkup:
    """Target language keyboard excluding source."""
    buttons = []
    row = []
    
    for code, lang in LANGUAGES.items():
        if code == source_lang:
            continue
        btn = InlineKeyboardButton(
            f"{lang.flag} {lang.name_native}",
            callback_data=f"{callback_prefix}:{code}"
        )
        row.append(btn)
        if len(row) == 3:
            buttons.append(row)
            row = []
    
    if row:
        buttons.append(row)
    
    buttons.append([InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="back:main")])
    return InlineKeyboardMarkup(buttons)


# ============== AUDIO PROCESSING ==============
async def convert_audio_to_mp3(audio_data: bytes, original_format: str = "ogg") -> Tuple[Optional[bytes], Optional[str]]:
    """Convert audio to MP3."""
    try:
        def _convert():
            with tempfile.NamedTemporaryFile(suffix=f".{original_format}", delete=False) as f:
                f.write(audio_data)
                input_path = f.name
            
            try:
                if original_format in ["ogg", "oga", "opus"]:
                    audio = AudioSegment.from_ogg(input_path)
                elif original_format == "mp3":
                    return audio_data, None
                elif original_format == "wav":
                    audio = AudioSegment.from_wav(input_path)
                elif original_format in ["m4a", "mp4"]:
                    audio = AudioSegment.from_file(input_path, format="m4a")
                else:
                    audio = AudioSegment.from_file(input_path)
                
                with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as out:
                    output_path = out.name
                
                audio.export(output_path, format="mp3", bitrate="128k")
                
                with open(output_path, "rb") as f:
                    mp3_data = f.read()
                
                os.unlink(output_path)
                return mp3_data, None
            finally:
                if os.path.exists(input_path):
                    os.unlink(input_path)
        
        return await asyncio.to_thread(_convert)
    except Exception as e:
        logger.error(f"Audio conversion error: {e}")
        return None, str(e)


# ============== GROQ WHISPER STT ==============
async def transcribe_with_whisper(audio_data: bytes) -> Tuple[Optional[str], Optional[str]]:
    """Transcribe with Groq Whisper including context prompt."""
    if not groq_client:
        return None, "Groq client not initialized"
    
    try:
        def _transcribe():
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
                f.write(audio_data)
                temp_path = f.name
            
            try:
                with open(temp_path, "rb") as audio_file:
                    result = groq_client.audio.transcriptions.create(
                        model=WHISPER_MODEL,
                        file=audio_file,
                        response_format="text",
                        language=None,  # Auto-detect
                        temperature=0.0,
                        prompt=WHISPER_CONTEXT_PROMPT,  # Context for better accuracy
                    )
                return result, None
            finally:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
        
        result, error = await asyncio.to_thread(_transcribe)
        
        if error:
            return None, error
        
        if result and len(result.strip()) > 0:
            logger.info(f"âœ… Whisper: {len(result)} chars")
            return result.strip(), None
        
        return None, "Empty transcription"
    
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Whisper error: {error_msg}")
        if "rate_limit" in error_msg.lower():
            return None, "rate_limit"
        return None, error_msg[:100]


# ============== GROQ LLM (FAST) ==============
async def process_with_groq(text: str, system_prompt: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """Process with Groq LLM (Fast mode)."""
    if not groq_client:
        return None, None, "Groq client not initialized"
    
    models = [GROQ_LLM_PRIMARY, GROQ_LLM_FALLBACK]
    
    for model in models:
        try:
            logger.info(f"âš¡ Groq: {model}")
            
            def _generate():
                return groq_client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"Process:\n\n{text}"}
                    ],
                    temperature=0.7,
                    max_tokens=8000,
                )
            
            response = await asyncio.to_thread(_generate)
            
            if response.choices and response.choices[0].message.content:
                result = response.choices[0].message.content.strip()
                logger.info(f"âœ… Groq success: {len(result)} chars")
                return result, f"âš¡ {model}", None
        
        except Exception as e:
            logger.warning(f"âŒ Groq {model}: {str(e)[:50]}")
            continue
    
    return None, None, "All Groq models failed"


# ============== SAMBANOVA LLM (PRO) ==============
async def process_with_sambanova(text: str, system_prompt: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """Process with SambaNova LLM (Pro mode)."""
    if not sambanova_client:
        return None, None, "SambaNova not available"
    
    models = [SAMBANOVA_MODEL_PRO, SAMBANOVA_MODEL_FALLBACK]
    
    for model in models:
        try:
            logger.info(f"ğŸš€ SambaNova: {model}")
            
            def _generate():
                return sambanova_client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"Process this transcription:\n\n{text}"}
                    ],
                    temperature=0.7,
                    max_tokens=8000,
                )
            
            response = await asyncio.to_thread(_generate)
            
            if response.choices and response.choices[0].message.content:
                result = response.choices[0].message.content.strip()
                logger.info(f"âœ… SambaNova success: {len(result)} chars")
                return result, f"ğŸš€ {model}", None
        
        except Exception as e:
            logger.warning(f"âŒ SambaNova {model}: {str(e)[:50]}")
            continue
    
    return None, None, "SambaNova failed"


# ============== UNIFIED PROCESSOR ==============
async def process_with_llm(
    text: str,
    system_prompt: str,
    engine: Engine
) -> Tuple[Optional[str], Optional[str], Optional[str], bool]:
    """
    Process with appropriate engine.
    Returns: (result, model_name, error, used_fallback)
    """
    used_fallback = False
    
    if engine == Engine.PRO:
        # Try SambaNova first
        if sambanova_client:
            result, model, error = await process_with_sambanova(text, system_prompt)
            if result:
                return result, model, None, False
            logger.warning("SambaNova failed, falling back to Groq")
        
        # Fallback to Groq
        used_fallback = True
    
    # Use Groq (Fast mode or fallback)
    result, model, error = await process_with_groq(text, system_prompt)
    return result, model, error, used_fallback


# ============== FULL PIPELINE ==============
async def process_audio_complete(
    audio_data: bytes,
    mime_type: str,
    mode: str,
    engine: Engine,
    lang: str = "fa",
    source_lang: Optional[str] = None,
    target_lang: Optional[str] = None,
) -> Dict:
    """Complete audio processing pipeline."""
    result = {
        "text": None,
        "transcription": None,
        "model": None,
        "error": None,
        "used_fallback": False,
    }
    
    # Format detection
    format_map = {
        "audio/ogg": "ogg", "audio/oga": "ogg", "audio/opus": "opus",
        "audio/mp3": "mp3", "audio/mpeg": "mp3",
        "audio/wav": "wav", "audio/x-wav": "wav",
        "audio/m4a": "m4a", "audio/mp4": "m4a",
    }
    original_format = format_map.get(mime_type, "ogg")
    
    # Convert to MP3
    if original_format != "mp3":
        mp3_data, _ = await convert_audio_to_mp3(audio_data, original_format)
        if not mp3_data:
            mp3_data = audio_data
    else:
        mp3_data = audio_data
    
    # Step 1: Transcribe with Whisper
    transcription, stt_error = await transcribe_with_whisper(mp3_data)
    
    if stt_error:
        if stt_error == "rate_limit":
            result["error"] = "âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Whisper. Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ ØµØ¨Ø± Ú©Ù†ÛŒØ¯."
        else:
            result["error"] = f"âŒ Ø®Ø·Ø§ Ø¯Ø± STT: {stt_error}"
        return result
    
    if not transcription:
        result["error"] = "âŒ Ù…ØªÙ†ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯."
        return result
    
    result["transcription"] = transcription
    
    # Step 2: Get appropriate prompt and process
    if mode == "transcript":
        prompt = get_transcript_prompt(lang, engine)
    elif mode == "lecture":
        prompt = get_lecture_prompt_pro(lang) if engine == Engine.PRO else get_lecture_prompt_fast(lang)
    elif mode == "soap":
        prompt = get_soap_prompt_pro() if engine == Engine.PRO else get_soap_prompt_fast()
    elif mode == "summary":
        prompt = get_summary_prompt(lang, engine)
    elif mode == "lyrics":
        prompt = get_lyrics_prompt(engine)
    elif mode == "translate":
        if not source_lang or not target_lang:
            result["error"] = "âŒ Ø²Ø¨Ø§Ù† Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡"
            return result
        prompt = get_translation_prompt(source_lang, target_lang, engine)
    else:
        prompt = get_transcript_prompt(lang, engine)
    
    # Process with LLM
    text, model, llm_error, used_fallback = await process_with_llm(transcription, prompt, engine)
    
    result["text"] = text
    result["model"] = model
    result["used_fallback"] = used_fallback
    
    if llm_error and not text:
        result["error"] = f"âŒ {llm_error}"
    
    return result


# ============== TELEGRAM HANDLERS ==============
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(MESSAGES["welcome"], parse_mode="Markdown")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    help_text = """ğŸ“– **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Omni-Hear AI v6.0**

**ğŸ”¹ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡:**
1ï¸âƒ£ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯
2ï¸âƒ£ Ø­Ø§Ù„Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:
   â€¢ âš¡ Ø³Ø±ÛŒØ¹ = Ù¾Ø§Ø³Ø® ÙÙˆØ±ÛŒ
   â€¢ ğŸš€ Ø¯Ù‚ÛŒÙ‚ = Ú©ÛŒÙÛŒØª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ

**ğŸ”¹ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§:**
â€¢ ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ - Ù…ØªÙ† Ú©Ø§Ù…Ù„ ØµÙˆØª
â€¢ ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡ - ÙØµÙ„ Ú©ØªØ§Ø¨ Ø¯Ø±Ø³ÛŒ
â€¢ ğŸ©º Ù¾Ø²Ø´Ú©ÛŒ - SOAP Note Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
â€¢ ğŸ“ Ø®Ù„Ø§ØµÙ‡ - Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´Ù…Ù†Ø¯
â€¢ ğŸµ Ù…ØªÙ† Ø¢Ù‡Ù†Ú¯ - Ù„ÛŒØ±ÛŒÚ©
â€¢ ğŸŒ ØªØ±Ø¬Ù…Ù‡ - Û· Ø²Ø¨Ø§Ù†

**ğŸ”¹ Ù…ÙˆØªÙˆØ±Ù‡Ø§:**
â€¢ âš¡ Groq Llama 70B (~Û³ Ø«Ø§Ù†ÛŒÙ‡)
â€¢ ğŸš€ SambaNova Llama 405B (Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ)

**ğŸ”¹ Ø¯Ø³ØªÙˆØ±Ø§Øª:**
/start - Ø´Ø±ÙˆØ¹
/help - Ø±Ø§Ù‡Ù†Ù…Ø§
/status - ÙˆØ¶Ø¹ÛŒØª"""
    
    await update.message.reply_text(help_text, parse_mode="Markdown")


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    status = ["ğŸ” **ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…**\n"]
    
    if groq_client:
        status.append("âœ… **Groq (STT + Fast):** ÙØ¹Ø§Ù„")
    else:
        status.append("âŒ **Groq:** ØºÛŒØ±ÙØ¹Ø§Ù„")
    
    if sambanova_client:
        status.append("âœ… **SambaNova (Pro 405B):** ÙØ¹Ø§Ù„")
    else:
        status.append("âš ï¸ **SambaNova:** ØºÛŒØ±ÙØ¹Ø§Ù„")
    
    status.append(f"\n**ğŸ¤– Ù…Ø¯Ù„â€ŒÙ‡Ø§:**")
    status.append(f"â€¢ STT: `{WHISPER_MODEL}`")
    status.append(f"â€¢ Fast: `{GROQ_LLM_PRIMARY}`")
    status.append(f"â€¢ Pro: `{SAMBANOVA_MODEL_PRO}`")
    
    flags = " ".join([l.flag for l in LANGUAGES.values()])
    status.append(f"\n**ğŸŒ Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§:** {flags}")
    
    await update.message.reply_text("\n".join(status), parse_mode="Markdown")


async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle audio files."""
    user_id = update.effective_user.id
    msg = update.message
    
    if not groq_client:
        await msg.reply_text(MESSAGES["api_missing"].format(missing="GROQ_API_KEY"))
        return
    
    # Get audio
    audio_file = None
    if msg.voice:
        audio_file = msg.voice
    elif msg.audio:
        audio_file = msg.audio
    elif msg.document and msg.document.mime_type and msg.document.mime_type.startswith("audio/"):
        audio_file = msg.document
    else:
        await msg.reply_text(MESSAGES["not_audio"])
        return
    
    # Size check
    file_size = getattr(audio_file, 'file_size', 0)
    if file_size and file_size > MAX_FILE_SIZE:
        await msg.reply_text(MESSAGES["file_too_large"])
        return
    
    try:
        file = await context.bot.get_file(audio_file.file_id)
        audio_bytes = await file.download_as_bytearray()
        
        mime_type = "audio/ogg" if msg.voice else getattr(audio_file, 'mime_type', 'audio/mpeg')
        
        user_audio_cache[user_id] = {
            "data": bytes(audio_bytes),
            "mime_type": mime_type,
            "size": len(audio_bytes),
        }
        
        # Clear state
        user_state.pop(user_id, None)
        
        size_kb = len(audio_bytes) / 1024
        size_str = f"{size_kb:.1f} KB" if size_kb < 1024 else f"{size_kb/1024:.1f} MB"
        
        await msg.reply_text(
            MESSAGES["audio_received"].format(size=size_str),
            reply_markup=get_main_menu_keyboard(),
            parse_mode="Markdown"
        )
    
    except Exception as e:
        logger.error(f"Audio error: {e}")
        await msg.reply_text(MESSAGES["error"])


async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle button callbacks."""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    data = query.data
    parts = data.split(":")
    action = parts[0]
    
    # Back button
    if action == "back":
        if user_id in user_audio_cache:
            size_kb = user_audio_cache[user_id]["size"] / 1024
            size_str = f"{size_kb:.1f} KB" if size_kb < 1024 else f"{size_kb/1024:.1f} MB"
            await query.edit_message_text(
                MESSAGES["audio_received"].format(size=size_str),
                reply_markup=get_main_menu_keyboard(),
                parse_mode="Markdown"
            )
        else:
            await query.edit_message_text(MESSAGES["no_audio"])
        user_state.pop(user_id, None)
        return
    
    # Mode selection: mode:type:engine
    if action == "mode":
        mode = parts[1]
        engine_str = parts[2]
        engine = Engine.PRO if engine_str == "pro" else Engine.FAST
        
        if user_id not in user_audio_cache:
            await query.edit_message_text(MESSAGES["no_audio"])
            return
        
        # Store engine preference
        user_state[user_id] = {"engine": engine}
        
        # Modes needing language selection
        if mode in ["transcript", "lecture", "summary"]:
            user_state[user_id]["mode"] = mode
            await query.edit_message_text(
                MESSAGES["select_language"],
                reply_markup=get_language_keyboard(f"lang:{mode}:{engine_str}"),
                parse_mode="Markdown"
            )
            return
        
        # Translation needs source + target
        if mode == "translate":
            user_state[user_id]["mode"] = mode
            await query.edit_message_text(
                MESSAGES["select_source_lang"],
                reply_markup=get_language_keyboard(f"source:{engine_str}"),
                parse_mode="Markdown"
            )
            return
        
        # SOAP and Lyrics - process directly
        await process_and_respond(query, context, user_id, mode, engine)
        return
    
    # Language selection: lang:mode:engine:code
    if action == "lang":
        mode = parts[1]
        engine_str = parts[2]
        lang = parts[3]
        engine = Engine.PRO if engine_str == "pro" else Engine.FAST
        await process_and_respond(query, context, user_id, mode, engine, lang=lang)
        return
    
    # Source language: source:engine:code
    if action == "source":
        engine_str = parts[1]
        source_lang = parts[2]
        user_state[user_id]["source_lang"] = source_lang
        await query.edit_message_text(
            MESSAGES["select_target_lang"],
            reply_markup=get_target_language_keyboard(source_lang, f"target:{engine_str}"),
            parse_mode="Markdown"
        )
        return
    
    # Target language: target:engine:code
    if action == "target":
        engine_str = parts[1]
        target_lang = parts[2]
        engine = Engine.PRO if engine_str == "pro" else Engine.FAST
        source_lang = user_state.get(user_id, {}).get("source_lang", "en")
        await process_and_respond(
            query, context, user_id, "translate", engine,
            source_lang=source_lang, target_lang=target_lang
        )
        return


async def process_and_respond(
    query,
    context,
    user_id: int,
    mode: str,
    engine: Engine,
    lang: str = "fa",
    source_lang: Optional[str] = None,
    target_lang: Optional[str] = None,
) -> None:
    """Process and send response."""
    
    if user_id not in user_audio_cache:
        await query.edit_message_text(MESSAGES["no_audio"])
        return
    
    audio_info = user_audio_cache[user_id]
    
    mode_names = {
        "transcript": "ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ",
        "lecture": "ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡",
        "soap": "ğŸ©º SOAP Ù¾Ø²Ø´Ú©ÛŒ",
        "summary": "ğŸ“ Ø®Ù„Ø§ØµÙ‡",
        "lyrics": "ğŸµ Ù…ØªÙ† Ø¢Ù‡Ù†Ú¯",
        "translate": "ğŸŒ ØªØ±Ø¬Ù…Ù‡",
    }
    
    engine_name = "ğŸš€ Pro (405B)" if engine == Engine.PRO else "âš¡ Fast (70B)"
    
    try:
        # Show STT progress
        await query.edit_message_text(
            f"ğŸ¯ **{mode_names.get(mode)}** | {engine_name}\n\n{MESSAGES['processing_stt']}",
            parse_mode="Markdown"
        )
        
        # Process
        result = await process_audio_complete(
            audio_info["data"],
            audio_info["mime_type"],
            mode,
            engine,
            lang=lang,
            source_lang=source_lang,
            target_lang=target_lang,
        )
        
        if result["error"]:
            await query.edit_message_text(result["error"])
            return
        
        if not result["text"]:
            await query.edit_message_text(MESSAGES["error"])
            return
        
        # Build response
        header = f"âœ… **{mode_names.get(mode)}**\n"
        
        if mode == "translate" and source_lang and target_lang:
            src = LANGUAGES.get(source_lang)
            tgt = LANGUAGES.get(target_lang)
            header += f"{src.flag} â†’ {tgt.flag}\n"
        
        header += "\n"
        
        # Footer with model info
        footer = f"\n\n---\nğŸ¤– `{result['model']}`"
        if result["used_fallback"]:
            footer += f"\nâš ï¸ {MESSAGES['pro_unavailable']}"
        
        full_text = header + result["text"] + footer
        
        # Send (handle long messages)
        if len(full_text) > 4000:
            await query.edit_message_text(full_text[:4000], parse_mode="Markdown")
            remaining = full_text[4000:]
            while remaining:
                chunk = remaining[:4000]
                remaining = remaining[4000:]
                await asyncio.sleep(0.3)
                await context.bot.send_message(
                    chat_id=query.message.chat_id,
                    text=chunk,
                    parse_mode="Markdown"
                )
        else:
            try:
                await query.edit_message_text(full_text, parse_mode="Markdown")
            except:
                await query.edit_message_text(full_text)
    
    except Exception as e:
        logger.error(f"Process error: {e}")
        logger.error(traceback.format_exc())
        await query.edit_message_text(f"âŒ Ø®Ø·Ø§: {str(e)[:100]}")
    
    finally:
        user_audio_cache.pop(user_id, None)
        user_state.pop(user_id, None)


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.error(f"Error: {context.error}")


# ============== MAIN ==============
def main() -> None:
    print("\n" + "=" * 70)
    print("  ğŸ§ OMNI-HEAR AI v6.0 - DUAL-ENGINE EDITION")
    print("  âš¡ Fast (Groq 70B) | ğŸš€ Pro (SambaNova 405B)")
    print("=" * 70)
    
    if not TELEGRAM_BOT_TOKEN:
        print("âŒ TELEGRAM_BOT_TOKEN not set!")
        sys.exit(1)
    
    if not GROQ_API_KEY:
        print("âŒ GROQ_API_KEY not set!")
        sys.exit(1)
    
    print(f"âœ… Telegram: Ready")
    print(f"âœ… Groq (STT + Fast): Ready")
    print(f"{'âœ…' if SAMBANOVA_API_KEY else 'âš ï¸'} SambaNova (Pro): {'Ready' if SAMBANOVA_API_KEY else 'Not configured'}")
    print(f"\nğŸŒ Languages: {', '.join([l.flag for l in LANGUAGES.values()])}")
    print("=" * 70 + "\n")
    
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("status", status_command))
    app.add_handler(MessageHandler(
        filters.VOICE | filters.AUDIO | filters.Document.AUDIO,
        handle_audio
    ))
    app.add_handler(CallbackQueryHandler(button_callback))
    app.add_error_handler(error_handler)
    
    logger.info("ğŸš€ Starting bot...")
    app.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)


if __name__ == "__main__":
    main()
