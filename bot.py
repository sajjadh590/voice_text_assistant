#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                OMNI-HEAR AI v7.0 (AssemblyAI + Groq Edition)                 â•‘
â•‘         ğŸ¤ AssemblyAI STT | ğŸ§  Groq Dual-LLM | ğŸ”„ Persistent Sessions        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ¤ STT: AssemblyAI (Best-in-class accuracy + Language Detection)            â•‘
â•‘  âš¡ Fast LLM: Groq Llama 3.1 8B Instant                                      â•‘
â•‘  ğŸ§  Complex LLM: Groq Llama 3.3 70B Versatile                                â•‘
â•‘  ğŸ”„ Persistent Audio: Process same file multiple times                       â•‘
â•‘  ğŸŒ 7 Languages | Auto Language Detection | Progress Tracking                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import logging
import asyncio
import tempfile
import traceback
import time
from typing import Optional, Dict, Tuple
from dataclasses import dataclass
from enum import Enum

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

import assemblyai as aai
from groq import Groq
from pydub import AudioSegment

# ============== LOGGING ==============
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ============== CONFIGURATION ==============
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
ASSEMBLYAI_API_KEY = os.getenv("ASSEMBLYAI_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# ============== API CLIENTS ==============
groq_client: Optional[Groq] = None
aai_transcriber = None

# Initialize AssemblyAI
if ASSEMBLYAI_API_KEY:
    aai.settings.api_key = ASSEMBLYAI_API_KEY
    logger.info("âœ… AssemblyAI configured")
else:
    logger.error("âŒ ASSEMBLYAI_API_KEY not set!")

# Initialize Groq
if GROQ_API_KEY:
    groq_client = Groq(api_key=GROQ_API_KEY)
    logger.info("âœ… Groq client initialized")
else:
    logger.error("âŒ GROQ_API_KEY not set!")

# ============== MODEL CONFIGURATION ==============
# Groq Models
GROQ_MODEL_FAST = "llama-3.1-8b-instant"        # Fast: Transcript, Lyrics, Quick tasks
GROQ_MODEL_COMPLEX = "llama-3.3-70b-versatile"  # Complex: Lecture, SOAP, Detailed tasks

MAX_FILE_SIZE = 20 * 1024 * 1024  # 20MB (Telegram limit)


# ============== TASK COMPLEXITY ==============
class TaskComplexity(Enum):
    FAST = "fast"       # Simple tasks - 8B model
    COMPLEX = "complex"  # Heavy tasks - 70B model


# Mode to complexity mapping
MODE_COMPLEXITY = {
    "transcript": TaskComplexity.FAST,
    "lyrics": TaskComplexity.FAST,
    "summary_quick": TaskComplexity.FAST,
    "translate_quick": TaskComplexity.FAST,
    "lecture": TaskComplexity.COMPLEX,
    "soap": TaskComplexity.COMPLEX,
    "summary_detailed": TaskComplexity.COMPLEX,
    "translate_detailed": TaskComplexity.COMPLEX,
}


# ============== LANGUAGES ==============
@dataclass
class Language:
    code: str
    name_en: str
    name_native: str
    flag: str
    assemblyai_code: str  # AssemblyAI language code


LANGUAGES: Dict[str, Language] = {
    "fa": Language("fa", "Persian", "ÙØ§Ø±Ø³ÛŒ", "ğŸ‡®ğŸ‡·", "fa"),
    "en": Language("en", "English", "English", "ğŸ‡¬ğŸ‡§", "en"),
    "fr": Language("fr", "French", "FranÃ§ais", "ğŸ‡«ğŸ‡·", "fr"),
    "es": Language("es", "Spanish", "EspaÃ±ol", "ğŸ‡ªğŸ‡¸", "es"),
    "ru": Language("ru", "Russian", "Ğ ÑƒÑÑĞºĞ¸Ğ¹", "ğŸ‡·ğŸ‡º", "ru"),
    "de": Language("de", "German", "Deutsch", "ğŸ‡©ğŸ‡ª", "de"),
    "ar": Language("ar", "Arabic", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "ğŸ‡¸ğŸ‡¦", "ar"),
}

# AssemblyAI language code to our code mapping
AAI_LANG_MAP = {
    "fa": "fa", "en": "en", "en_us": "en", "en_uk": "en", "en_au": "en",
    "fr": "fr", "es": "es", "ru": "ru", "de": "de", "ar": "ar",
}


# ============== USER STATE (PERSISTENT) ==============
user_audio_cache: Dict[int, dict] = {}  # Stores audio data
user_state: Dict[int, dict] = {}        # Stores workflow state


def get_cached_audio(user_id: int) -> Optional[dict]:
    """Get cached audio for user."""
    return user_audio_cache.get(user_id)


def clear_user_cache(user_id: int):
    """Clear all cached data for user."""
    user_audio_cache.pop(user_id, None)
    user_state.pop(user_id, None)


# ============== SYSTEM PROMPTS ==============

def get_transcript_prompt(detected_lang: str) -> str:
    """Simple transcript formatting prompt."""
    lang = LANGUAGES.get(detected_lang, LANGUAGES["en"])
    return f"""You are a professional transcription editor.

TASK: Clean and format this raw transcription.

RULES:
1. Fix obvious errors while preserving meaning
2. Add proper punctuation (. , ? ! :)
3. Create logical paragraphs
4. Mark multiple speakers as [Speaker 1], [Speaker 2]
5. Keep the ORIGINAL language ({lang.name_en})
6. Preserve mixed-language words as-is

OUTPUT: Formatted transcription in {lang.name_en}."""


def get_lecture_prompt(detected_lang: str) -> str:
    """Academic lecture prompt - outputs in detected language."""
    lang = LANGUAGES.get(detected_lang, LANGUAGES["fa"])
    
    if detected_lang == "fa":
        return """Ù†Ù‚Ø´: Ø§Ø³ØªØ§Ø¯ Ø¨Ø±Ø¬Ø³ØªÙ‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¨Ø§ ØªØ¬Ø±Ø¨Ù‡ Û²Û° Ø³Ø§Ù„Ù‡ Ø¯Ø± ØªØ¯Ø±ÛŒØ³ Ùˆ Ù†Ú¯Ø§Ø±Ø´ Ú©ØªØ¨ Ù…Ø±Ø¬Ø¹.

ÙˆØ¸ÛŒÙÙ‡: ØªØ¨Ø¯ÛŒÙ„ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ Ø§ÛŒÙ† ØµÙˆØª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ù‡ ÛŒÚ© **ÙØµÙ„ Ø¬Ø§Ù…Ø¹ Ú©ØªØ§Ø¨ Ø¯Ø±Ø³ÛŒ** Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      ğŸ“š ÙØµÙ„ Ø¯Ø±Ø³ÛŒ Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ø³Ø§Ø®ØªØ§Ø± Ø§Ù„Ø²Ø§Ù…ÛŒ:

**Û±. Ù…Ù‚Ø¯Ù…Ù‡ Ø¹Ù„Ù…ÛŒ**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- ØªØ¹Ø±ÛŒÙ Ù…ÙˆØ¶ÙˆØ¹
- Ø§Ù‡Ù…ÛŒØª Ø¹Ù„Ù…ÛŒ/Ø¨Ø§Ù„ÛŒÙ†ÛŒ
- Ø§Ù‡Ø¯Ø§Ù ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ

**Û². Ù…ØªÙ† Ø§ØµÙ„ÛŒ**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ **Ø¹Ù†Ø§ÙˆÛŒÙ† Ø¨ÙˆÙ„Ø¯**
- ØªÙˆØ¶ÛŒØ­ Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… Ø§Ø² Ø³Ø§Ø¯Ù‡ Ø¨Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
- Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ

**Û³. Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ (Clinical Pearls) ğŸ’**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Ù†Ú©Ø§Øª Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ú©Ø±Ø¯Ù†
- Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø±Ø§ÛŒØ¬

**Û´. Ø¬Ø¯ÙˆÙ„ Ø®Ù„Ø§ØµÙ‡ ğŸ“Š**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
| Ù…ÙˆØ¶ÙˆØ¹ | ØªÙˆØ¶ÛŒØ­ |
|-------|-------|

**Ûµ. Ø®Ù„Ø§ØµÙ‡ ÙØµÙ„**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Ù…Ø±ÙˆØ± Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ

**Û¶. Ø³Ø¤Ø§Ù„Ø§Øª Ù…Ø±ÙˆØ±ÛŒ**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- Û³ Ø³Ø¤Ø§Ù„ Ø®ÙˆØ¯Ø¢Ø²Ù…Ø§ÛŒÛŒ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ø§Ù„Ø²Ø§Ù…Ø§Øª Ù†Ú¯Ø§Ø±Ø´ÛŒ:
â€¢ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±Ø³Ù…ÛŒ Ùˆ Ø¢Ú©Ø§Ø¯Ù…ÛŒÚ©
â€¢ Ø§ØµØ·Ù„Ø§Ø­Ø§Øª ØªØ®ØµØµÛŒ ÙØ§Ø±Ø³ÛŒ + (Ù…Ø¹Ø§Ø¯Ù„ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
â€¢ Ø¨Ø¯ÙˆÙ† Ú©Ù„Ù…Ø§Øª Ø¹Ø§Ù…ÛŒØ§Ù†Ù‡

Ø²Ø¨Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ: ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ"""

    elif detected_lang == "ar":
        return """Ø§Ù„Ø¯ÙˆØ±: Ø£Ø³ØªØ§Ø° Ø¬Ø§Ù…Ø¹ÙŠ Ù…ØªÙ…ÙŠØ².
Ø§Ù„Ù…Ù‡Ù…Ø©: ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙØµÙ„ ÙƒØªØ§Ø¨ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø´Ø§Ù…Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
Ø§Ù„Ù‡ÙŠÙƒÙ„: Ù…Ù‚Ø¯Ù…Ø©ØŒ Ù…Ø­ØªÙˆÙ‰ Ø±Ø¦ÙŠØ³ÙŠ Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ†ØŒ Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©ØŒ Ø¬Ø¯ÙˆÙ„ØŒ Ù…Ù„Ø®ØµØŒ Ø£Ø³Ø¦Ù„Ø©.
Ù„ØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·"""

    else:
        return f"""Role: Distinguished University Professor with 20+ years of teaching experience.

Task: Transform this transcription into a comprehensive **Textbook Chapter** in {lang.name_en}.

STRUCTURE:

## 1. Introduction
- Topic definition
- Scientific importance
- Learning objectives

## 2. Main Content
- Organized with **bold headers**
- Step-by-step explanations
- Practical examples

## 3. Clinical Pearls ğŸ’
- Key points to remember
- Common mistakes

## 4. Summary Table ğŸ“Š
| Topic | Description |
|-------|-------------|

## 5. Chapter Summary
- Key points review

## 6. Review Questions
- 3 self-assessment questions

OUTPUT LANGUAGE: {lang.name_en} ONLY"""


def get_soap_prompt() -> str:
    """Medical SOAP note - always English."""
    return """Role: Senior Board-Certified Attending Physician.

Task: Transform this medical dictation into a US Medical Standard SOAP Note.

FORMAT:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         SOAP NOTE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ **SUBJECTIVE**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Chief Complaint (CC):** [Patient's words]

**History of Present Illness (HPI):**
- Onset:
- Location:
- Duration:
- Character:
- Aggravating/Alleviating:
- Severity (1-10):

**Review of Systems (ROS):**
â–¡ Constitutional | â–¡ HEENT | â–¡ Cardiovascular | â–¡ Respiratory
â–¡ GI | â–¡ GU | â–¡ MSK | â–¡ Neuro | â–¡ Psych | â–¡ Skin

**PMH:** | **PSH:** | **Medications:** | **Allergies:**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”¬ **OBJECTIVE**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Vitals:** BP: /mmHg | HR: bpm | RR: /min | Temp: Â°F | SpO2: %

**Physical Exam:**
- General:
- HEENT:
- Cardiovascular:
- Pulmonary:
- Abdomen:
- Extremities:
- Neuro:

**Labs/Imaging:**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ **ASSESSMENT**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Primary Diagnosis:** [Diagnosis] â€” ICD-10: [Code]

**Differential:**
1. [DDx 1]
2. [DDx 2]
3. [DDx 3]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ **PLAN**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Diagnostics:** [ ]
**Treatment:** [ ]
**Medications:** [ ]
**Patient Education:** [ ]
**Follow-up:** [ ]
**Referrals:** [ ]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RULES:
1. OUTPUT IN ENGLISH ONLY
2. Correct medical terminology errors
3. Include ICD-10 codes
4. Mark missing info as "Not documented"

OUTPUT LANGUAGE: ENGLISH ONLY"""


def get_summary_prompt(detected_lang: str, detailed: bool = False) -> str:
    """Summary prompt."""
    lang = LANGUAGES.get(detected_lang, LANGUAGES["fa"])
    
    if detailed:
        return f"""Role: Expert Content Analyst.

Task: Create a comprehensive summary in {lang.name_en}.

FORMAT:

ğŸ“Œ **Executive Summary**
[3-4 sentences]

ğŸ“‹ **Key Points**
â€¢ [Point 1]
â€¢ [Point 2]
â€¢ [Point 3]
...

ğŸ’¡ **Important Details**
[Names, numbers, specifics]

ğŸ¯ **Conclusions**
[Main takeaways]

âœ… **Action Items** (if any)

OUTPUT: {lang.name_en} only"""
    else:
        return f"""Summarize this content in {lang.name_en}.

Format:
â€¢ Overview (2 sentences)
â€¢ Key points (bullets)
â€¢ Conclusion

OUTPUT: {lang.name_en} only."""


def get_lyrics_prompt() -> str:
    """Lyrics extraction prompt."""
    return """Extract and format lyrics OR speech from this transcription.

FOR MUSIC:
ğŸµ **Song Info** (if identifiable)
- Title:
- Artist:

[Verse 1]
Lines...

[Chorus]
Lines...

[Verse 2]
...

FOR SPEECH:
Clean paragraphs with speaker identification.

RULES:
1. Keep ORIGINAL language
2. Mark unclear: [...]
3. Mark instrumental: [ğŸ¸ Instrumental]

OUTPUT: Original language, formatted."""


def get_translation_prompt(source_lang: str, target_lang: str, detailed: bool = False) -> str:
    """Translation prompt."""
    source = LANGUAGES.get(source_lang, LANGUAGES["en"])
    target = LANGUAGES.get(target_lang, LANGUAGES["fa"])
    
    if detailed:
        return f"""Role: Expert Translator fluent in {source.name_en} and {target.name_en}.

Task: Translate from {source.name_en} to {target.name_en}.

PRINCIPLES:
1. Preserve complete meaning
2. Use natural, idiomatic {target.name_en}
3. Maintain tone and style
4. Keep proper nouns
5. Translate idioms to equivalents

OUTPUT FORMAT:

ğŸ“ **Translation:**
[Full translation]

---

ğŸ“Œ **Summary:**
[2 sentences about content]

OUTPUT: {target.name_en} only"""
    else:
        return f"""Translate from {source.name_en} to {target.name_en}.
Keep meaning, use natural language.
OUTPUT: {target.name_en} only."""


# ============== UI MESSAGES ==============
MESSAGES = {
    "welcome": """ğŸ§ **Ø¨Ù‡ Omni-Hear AI Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!**

ğŸš€ **Ù†Ø³Ø®Ù‡ 7.0 - AssemblyAI + Groq**

**ğŸ¤ Ù…ÙˆØªÙˆØ± Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ:** AssemblyAI (Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§)
**âš¡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹:** Llama 8B
**ğŸ§  Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡:** Llama 70B

ğŸ“¤ **ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯**

ğŸ”„ **Ù‚Ø§Ø¨Ù„ÛŒØª Ø¬Ø¯ÛŒØ¯:** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ø±ÙˆÛŒ ÛŒÚ© ÙØ§ÛŒÙ„!

ğŸŒ **Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§:**
ğŸ‡®ğŸ‡· ÙØ§Ø±Ø³ÛŒ | ğŸ‡¬ğŸ‡§ English | ğŸ‡«ğŸ‡· FranÃ§ais
ğŸ‡ªğŸ‡¸ EspaÃ±ol | ğŸ‡©ğŸ‡ª Deutsch | ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©""",

    "audio_received": """ğŸµ **ÙØ§ÛŒÙ„ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯!** ({size})

âš¡ **Ø³Ø±ÛŒØ¹** = Ù¾Ø§Ø³Ø® ÙÙˆØ±ÛŒ (8B)
ğŸ§  **Ù¾ÛŒØ´Ø±ÙØªÙ‡** = Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ (70B)

ğŸ”„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ Ø¹Ù…Ù„ÛŒØ§Øª Ø±ÙˆÛŒ Ù‡Ù…ÛŒÙ† ÙØ§ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯!

ğŸ“‹ Ù†ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:""",

    "processing_stt": "ğŸ¤ **Ù…Ø±Ø­Ù„Ù‡ Û±/Û²:** Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ Ø¨Ø§ AssemblyAI...\n\nâ³ Ù¾ÛŒØ´Ø±ÙØª: {progress}%",
    "processing_llm_fast": "ğŸ§  **Ù…Ø±Ø­Ù„Ù‡ Û²/Û²:** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Llama 8B...\n\nâ³ Ù¾ÛŒØ´Ø±ÙØª: {progress}%",
    "processing_llm_complex": "ğŸ§  **Ù…Ø±Ø­Ù„Ù‡ Û²/Û²:** Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Llama 70B...\n\nâ³ Ù¾ÛŒØ´Ø±ÙØª: {progress}%",
    
    "operation_complete": "âœ… **Ø¹Ù…Ù„ÛŒØ§Øª {mode} Ú©Ø§Ù…Ù„ Ø´Ø¯!**\n\nğŸ”„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¹Ù…Ù„ÛŒØ§Øª Ø¯ÛŒÚ¯Ø±ÛŒ Ø±ÙˆÛŒ Ù‡Ù…ÛŒÙ† ÙØ§ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯.",
    
    "select_language": "ğŸŒ **Ø²Ø¨Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:**",
    "select_source_lang": "ğŸ—£ **Ø²Ø¨Ø§Ù† ØµÙˆØª (Ù…Ø¨Ø¯Ø§):**",
    "select_target_lang": "ğŸ¯ **Ø²Ø¨Ø§Ù† ØªØ±Ø¬Ù…Ù‡ (Ù…Ù‚ØµØ¯):**",
    
    "detected_language": "ğŸ” **Ø²Ø¨Ø§Ù† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:** {lang}",
    
    "error": "âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
    "error_detail": "âŒ Ø®Ø·Ø§: {detail}",
    "no_audio": "âš ï¸ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.",
    "file_too_large": "âš ï¸ Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø² Û²Û° Ù…Ú¯Ø§Ø¨Ø§ÛŒØª Ø§Ø³Øª.",
    "not_audio": "âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ (MP3, OGG, WAV, M4A).",
    "api_missing": "âš ï¸ Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡: {missing}",
    "session_expired": "âš ï¸ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.",
}


# ============== KEYBOARDS ==============
def get_main_menu_keyboard() -> InlineKeyboardMarkup:
    """Main menu with dual options."""
    return InlineKeyboardMarkup([
        # Transcript
        [
            InlineKeyboardButton("ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ âš¡", callback_data="mode:transcript:fast"),
        ],
        # Lecture
        [
            InlineKeyboardButton("ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡ ğŸ§ ", callback_data="mode:lecture:complex"),
        ],
        # Medical SOAP
        [
            InlineKeyboardButton("ğŸ©º SOAP Ù¾Ø²Ø´Ú©ÛŒ ğŸ§ ", callback_data="mode:soap:complex"),
        ],
        # Summary
        [
            InlineKeyboardButton("ğŸ“ Ø®Ù„Ø§ØµÙ‡ âš¡", callback_data="mode:summary_quick:fast"),
            InlineKeyboardButton("ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ ğŸ§ ", callback_data="mode:summary_detailed:complex"),
        ],
        # Lyrics
        [
            InlineKeyboardButton("ğŸµ Ù…ØªÙ† Ø¢Ù‡Ù†Ú¯ âš¡", callback_data="mode:lyrics:fast"),
        ],
        # Translation
        [
            InlineKeyboardButton("ğŸŒ ØªØ±Ø¬Ù…Ù‡ âš¡", callback_data="mode:translate_quick:fast"),
            InlineKeyboardButton("ğŸŒ ØªØ±Ø¬Ù…Ù‡ Ø¯Ù‚ÛŒÙ‚ ğŸ§ ", callback_data="mode:translate_detailed:complex"),
        ],
        # Clear session
        [
            InlineKeyboardButton("ğŸ—‘ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„", callback_data="clear:session"),
        ],
    ])


def get_back_to_menu_keyboard() -> InlineKeyboardMarkup:
    """Back to menu button after operation."""
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ", callback_data="back:main")],
        [InlineKeyboardButton("ğŸ—‘ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ùˆ Ø®Ø±ÙˆØ¬", callback_data="clear:session")],
    ])


def get_language_keyboard(callback_prefix: str) -> InlineKeyboardMarkup:
    """Language selection keyboard."""
    buttons = []
    row = []
    
    for code, lang in LANGUAGES.items():
        btn = InlineKeyboardButton(
            f"{lang.flag} {lang.name_native}",
            callback_data=f"{callback_prefix}:{code}"
        )
        row.append(btn)
        if len(row) == 3:
            buttons.append(row)
            row = []
    
    if row:
        buttons.append(row)
    
    buttons.append([InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="back:main")])
    return InlineKeyboardMarkup(buttons)


def get_target_language_keyboard(source_lang: str, callback_prefix: str) -> InlineKeyboardMarkup:
    """Target language keyboard excluding source."""
    buttons = []
    row = []
    
    for code, lang in LANGUAGES.items():
        if code == source_lang:
            continue
        btn = InlineKeyboardButton(
            f"{lang.flag} {lang.name_native}",
            callback_data=f"{callback_prefix}:{code}"
        )
        row.append(btn)
        if len(row) == 3:
            buttons.append(row)
            row = []
    
    if row:
        buttons.append(row)
    
    buttons.append([InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="back:main")])
    return InlineKeyboardMarkup(buttons)


# ============== AUDIO PROCESSING ==============
async def convert_audio_to_mp3(audio_data: bytes, original_format: str = "ogg") -> Tuple[Optional[bytes], Optional[str]]:
    """Convert audio to MP3."""
    try:
        def _convert():
            with tempfile.NamedTemporaryFile(suffix=f".{original_format}", delete=False) as f:
                f.write(audio_data)
                input_path = f.name
            
            try:
                if original_format in ["ogg", "oga", "opus"]:
                    audio = AudioSegment.from_ogg(input_path)
                elif original_format == "mp3":
                    return audio_data, None
                elif original_format == "wav":
                    audio = AudioSegment.from_wav(input_path)
                elif original_format in ["m4a", "mp4"]:
                    audio = AudioSegment.from_file(input_path, format="m4a")
                else:
                    audio = AudioSegment.from_file(input_path)
                
                with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as out:
                    output_path = out.name
                
                audio.export(output_path, format="mp3", bitrate="128k")
                
                with open(output_path, "rb") as f:
                    mp3_data = f.read()
                
                os.unlink(output_path)
                return mp3_data, None
            finally:
                if os.path.exists(input_path):
                    os.unlink(input_path)
        
        return await asyncio.to_thread(_convert)
    except Exception as e:
        logger.error(f"Audio conversion error: {e}")
        return None, str(e)


# ============== ASSEMBLYAI STT ==============
async def transcribe_with_assemblyai(
    audio_data: bytes,
    progress_callback=None
) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """
    Transcribe with AssemblyAI using async polling.
    Returns: (transcription, detected_language, error)
    """
    if not ASSEMBLYAI_API_KEY:
        return None, None, "AssemblyAI not configured"
    
    try:
        # Save audio to temp file
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
            f.write(audio_data)
            temp_path = f.name
        
        try:
            # Configure transcriber with language detection
            config = aai.TranscriptionConfig(
                language_detection=True,  # Auto-detect language
                punctuate=True,
                format_text=True,
            )
            
            transcriber = aai.Transcriber()
            
            # Submit for transcription (async polling internally)
            if progress_callback:
                await progress_callback(10)
            
            def _transcribe():
                return transcriber.transcribe(temp_path, config=config)
            
            # Poll with progress updates
            if progress_callback:
                await progress_callback(20)
            
            transcript = await asyncio.to_thread(_transcribe)
            
            if progress_callback:
                await progress_callback(80)
            
            if transcript.status == aai.TranscriptStatus.error:
                return None, None, f"AssemblyAI error: {transcript.error}"
            
            if transcript.status == aai.TranscriptStatus.completed:
                text = transcript.text
                
                # Get detected language
                detected_lang = "en"  # Default
                if hasattr(transcript, 'language_code') and transcript.language_code:
                    detected_lang = AAI_LANG_MAP.get(transcript.language_code, "en")
                
                if progress_callback:
                    await progress_callback(100)
                
                logger.info(f"âœ… AssemblyAI: {len(text)} chars, lang={detected_lang}")
                return text, detected_lang, None
            
            return None, None, f"Unexpected status: {transcript.status}"
            
        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    
    except Exception as e:
        logger.error(f"AssemblyAI error: {e}")
        return None, None, str(e)[:100]


# ============== GROQ LLM ==============
async def process_with_groq(
    text: str,
    system_prompt: str,
    complexity: TaskComplexity,
    progress_callback=None
) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """Process with Groq LLM based on complexity."""
    if not groq_client:
        return None, None, "Groq not configured"
    
    # Select model based on complexity
    if complexity == TaskComplexity.FAST:
        models = [GROQ_MODEL_FAST, GROQ_MODEL_COMPLEX]
    else:
        models = [GROQ_MODEL_COMPLEX, GROQ_MODEL_FAST]
    
    for model in models:
        try:
            logger.info(f"ğŸ§  Groq: {model}")
            
            if progress_callback:
                await progress_callback(30)
            
            def _generate():
                return groq_client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"Process this transcription:\n\n{text}"}
                    ],
                    temperature=0.7,
                    max_tokens=8000,
                )
            
            if progress_callback:
                await progress_callback(60)
            
            response = await asyncio.to_thread(_generate)
            
            if progress_callback:
                await progress_callback(90)
            
            if response.choices and response.choices[0].message.content:
                result = response.choices[0].message.content.strip()
                
                if progress_callback:
                    await progress_callback(100)
                
                model_label = "âš¡ 8B" if model == GROQ_MODEL_FAST else "ğŸ§  70B"
                logger.info(f"âœ… Groq success: {len(result)} chars")
                return result, f"{model_label} ({model})", None
        
        except Exception as e:
            logger.warning(f"âŒ Groq {model}: {str(e)[:50]}")
            continue
    
    return None, None, "All Groq models failed"


# ============== FULL PIPELINE ==============
async def process_audio_complete(
    audio_data: bytes,
    mime_type: str,
    mode: str,
    complexity: TaskComplexity,
    target_lang: Optional[str] = None,
    source_lang: Optional[str] = None,
    progress_callback=None,
) -> Dict:
    """Complete audio processing pipeline."""
    result = {
        "text": None,
        "transcription": None,
        "detected_lang": None,
        "model": None,
        "error": None,
    }
    
    # Format detection
    format_map = {
        "audio/ogg": "ogg", "audio/oga": "ogg", "audio/opus": "opus",
        "audio/mp3": "mp3", "audio/mpeg": "mp3",
        "audio/wav": "wav", "audio/x-wav": "wav",
        "audio/m4a": "m4a", "audio/mp4": "m4a",
    }
    original_format = format_map.get(mime_type, "ogg")
    
    # Convert to MP3
    if original_format != "mp3":
        mp3_data, _ = await convert_audio_to_mp3(audio_data, original_format)
        if not mp3_data:
            mp3_data = audio_data
    else:
        mp3_data = audio_data
    
    # Step 1: Transcribe with AssemblyAI
    async def stt_progress(p):
        if progress_callback:
            await progress_callback("stt", p)
    
    transcription, detected_lang, stt_error = await transcribe_with_assemblyai(
        mp3_data, stt_progress
    )
    
    if stt_error:
        result["error"] = f"âŒ Ø®Ø·Ø§ÛŒ AssemblyAI: {stt_error}"
        return result
    
    if not transcription:
        result["error"] = "âŒ Ù…ØªÙ†ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯."
        return result
    
    result["transcription"] = transcription
    result["detected_lang"] = detected_lang
    
    # Step 2: Get appropriate prompt
    if mode == "transcript":
        prompt = get_transcript_prompt(detected_lang)
    elif mode == "lecture":
        prompt = get_lecture_prompt(detected_lang)
    elif mode == "soap":
        prompt = get_soap_prompt()
    elif mode in ["summary_quick", "summary_detailed"]:
        detailed = mode == "summary_detailed"
        prompt = get_summary_prompt(detected_lang, detailed)
    elif mode == "lyrics":
        prompt = get_lyrics_prompt()
    elif mode in ["translate_quick", "translate_detailed"]:
        if not source_lang:
            source_lang = detected_lang
        if not target_lang:
            result["error"] = "âŒ Ø²Ø¨Ø§Ù† Ù…Ù‚ØµØ¯ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡"
            return result
        detailed = mode == "translate_detailed"
        prompt = get_translation_prompt(source_lang, target_lang, detailed)
    else:
        prompt = get_transcript_prompt(detected_lang)
    
    # Step 3: Process with Groq
    async def llm_progress(p):
        if progress_callback:
            await progress_callback("llm", p)
    
    text, model, llm_error = await process_with_groq(
        transcription, prompt, complexity, llm_progress
    )
    
    result["text"] = text
    result["model"] = model
    
    if llm_error and not text:
        result["error"] = f"âŒ {llm_error}"
    
    return result


# ============== TELEGRAM HANDLERS ==============
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.effective_user.id
    clear_user_cache(user_id)
    await update.message.reply_text(MESSAGES["welcome"], parse_mode="Markdown")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    help_text = """ğŸ“– **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Omni-Hear AI v7.0**

**ğŸ”¹ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡:**
1ï¸âƒ£ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯
2ï¸âƒ£ Ù†ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯
3ï¸âƒ£ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ Ø¹Ù…Ù„ÛŒØ§Øª Ø±ÙˆÛŒ Ù‡Ù…ÛŒÙ† ÙØ§ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯!

**ğŸ”¹ Ù…ÙˆØªÙˆØ±Ù‡Ø§:**
â€¢ âš¡ **Ø³Ø±ÛŒØ¹ (8B):** Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒØŒ Ù„ÛŒØ±ÛŒÚ©ØŒ ØªØ±Ø¬Ù…Ù‡ Ø³Ø±ÛŒØ¹
â€¢ ğŸ§  **Ù¾ÛŒØ´Ø±ÙØªÙ‡ (70B):** Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡ØŒ SOAPØŒ Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹

**ğŸ”¹ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§:**
ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ | ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡ | ğŸ©º SOAP
ğŸ“ Ø®Ù„Ø§ØµÙ‡ | ğŸµ Ù„ÛŒØ±ÛŒÚ© | ğŸŒ ØªØ±Ø¬Ù…Ù‡

**ğŸ”¹ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¬Ø¯ÛŒØ¯:**
ğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ø±ÙˆÛŒ ÛŒÚ© ÙØ§ÛŒÙ„!

**ğŸ”¹ Ø¯Ø³ØªÙˆØ±Ø§Øª:**
/start - Ø´Ø±ÙˆØ¹ Ù…Ø¬Ø¯Ø¯
/help - Ø±Ø§Ù‡Ù†Ù…Ø§
/status - ÙˆØ¶Ø¹ÛŒØª"""
    
    await update.message.reply_text(help_text, parse_mode="Markdown")


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.effective_user.id
    has_audio = user_id in user_audio_cache
    
    status = ["ğŸ” **ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ… v7.0**\n"]
    
    if ASSEMBLYAI_API_KEY:
        status.append("âœ… **AssemblyAI (STT):** ÙØ¹Ø§Ù„")
    else:
        status.append("âŒ **AssemblyAI:** ØºÛŒØ±ÙØ¹Ø§Ù„")
    
    if groq_client:
        status.append("âœ… **Groq (LLM):** ÙØ¹Ø§Ù„")
    else:
        status.append("âŒ **Groq:** ØºÛŒØ±ÙØ¹Ø§Ù„")
    
    status.append(f"\n**ğŸ¤– Ù…Ø¯Ù„â€ŒÙ‡Ø§:**")
    status.append(f"â€¢ Fast: `{GROQ_MODEL_FAST}`")
    status.append(f"â€¢ Complex: `{GROQ_MODEL_COMPLEX}`")
    
    status.append(f"\n**ğŸ“ ÙˆØ¶Ø¹ÛŒØª ÙØ§ÛŒÙ„ Ø´Ù…Ø§:**")
    if has_audio:
        size = user_audio_cache[user_id].get("size", 0) / 1024
        status.append(f"âœ… ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ ({size:.1f} KB)")
    else:
        status.append("âŒ ÙØ§ÛŒÙ„ÛŒ Ù†Ø¯Ø§Ø±ÛŒØ¯")
    
    flags = " ".join([l.flag for l in LANGUAGES.values()])
    status.append(f"\n**ğŸŒ Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§:** {flags}")
    
    await update.message.reply_text("\n".join(status), parse_mode="Markdown")


async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle audio files."""
    user_id = update.effective_user.id
    msg = update.message
    
    # Check APIs
    missing = []
    if not ASSEMBLYAI_API_KEY:
        missing.append("ASSEMBLYAI_API_KEY")
    if not GROQ_API_KEY:
        missing.append("GROQ_API_KEY")
    
    if missing:
        await msg.reply_text(MESSAGES["api_missing"].format(missing=", ".join(missing)))
        return
    
    # Get audio
    audio_file = None
    if msg.voice:
        audio_file = msg.voice
    elif msg.audio:
        audio_file = msg.audio
    elif msg.document and msg.document.mime_type and msg.document.mime_type.startswith("audio/"):
        audio_file = msg.document
    else:
        await msg.reply_text(MESSAGES["not_audio"])
        return
    
    # Size check
    file_size = getattr(audio_file, 'file_size', 0)
    if file_size and file_size > MAX_FILE_SIZE:
        await msg.reply_text(MESSAGES["file_too_large"])
        return
    
    try:
        file = await context.bot.get_file(audio_file.file_id)
        audio_bytes = await file.download_as_bytearray()
        
        mime_type = "audio/ogg" if msg.voice else getattr(audio_file, 'mime_type', 'audio/mpeg')
        
        # Store in persistent cache
        user_audio_cache[user_id] = {
            "data": bytes(audio_bytes),
            "mime_type": mime_type,
            "size": len(audio_bytes),
            "timestamp": time.time(),
        }
        
        # Clear old state
        user_state.pop(user_id, None)
        
        size_kb = len(audio_bytes) / 1024
        size_str = f"{size_kb:.1f} KB" if size_kb < 1024 else f"{size_kb/1024:.1f} MB"
        
        logger.info(f"âœ… Audio cached: user={user_id}, size={len(audio_bytes)}")
        
        await msg.reply_text(
            MESSAGES["audio_received"].format(size=size_str),
            reply_markup=get_main_menu_keyboard(),
            parse_mode="Markdown"
        )
    
    except Exception as e:
        logger.error(f"Audio error: {e}")
        await msg.reply_text(MESSAGES["error"])


async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle button callbacks."""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    data = query.data
    parts = data.split(":")
    action = parts[0]
    
    # Clear session
    if action == "clear":
        clear_user_cache(user_id)
        await query.edit_message_text(
            "ğŸ—‘ **ÙØ§ÛŒÙ„ Ù¾Ø§Ú© Ø´Ø¯.**\n\nğŸ“¤ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ù…Ø¬Ø¯Ø¯ØŒ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.",
            parse_mode="Markdown"
        )
        return
    
    # Back to main menu
    if action == "back":
        if user_id in user_audio_cache:
            size_kb = user_audio_cache[user_id]["size"] / 1024
            size_str = f"{size_kb:.1f} KB" if size_kb < 1024 else f"{size_kb/1024:.1f} MB"
            await query.edit_message_text(
                MESSAGES["audio_received"].format(size=size_str),
                reply_markup=get_main_menu_keyboard(),
                parse_mode="Markdown"
            )
        else:
            await query.edit_message_text(MESSAGES["session_expired"])
        user_state.pop(user_id, None)
        return
    
    # Mode selection: mode:type:complexity
    if action == "mode":
        mode = parts[1]
        complexity_str = parts[2]
        complexity = TaskComplexity.COMPLEX if complexity_str == "complex" else TaskComplexity.FAST
        
        if user_id not in user_audio_cache:
            await query.edit_message_text(MESSAGES["session_expired"])
            return
        
        # Store state
        user_state[user_id] = {
            "mode": mode,
            "complexity": complexity,
        }
        
        # Translation needs target language selection
        if mode in ["translate_quick", "translate_detailed"]:
            await query.edit_message_text(
                MESSAGES["select_target_lang"],
                reply_markup=get_language_keyboard(f"target:{complexity_str}"),
                parse_mode="Markdown"
            )
            return
        
        # Process directly for other modes
        await process_and_respond(query, context, user_id, mode, complexity)
        return
    
    # Target language for translation: target:complexity:code
    if action == "target":
        complexity_str = parts[1]
        target_lang = parts[2]
        complexity = TaskComplexity.COMPLEX if complexity_str == "complex" else TaskComplexity.FAST
        
        state = user_state.get(user_id, {})
        mode = state.get("mode", "translate_quick")
        
        await process_and_respond(
            query, context, user_id, mode, complexity,
            target_lang=target_lang
        )
        return


async def process_and_respond(
    query,
    context,
    user_id: int,
    mode: str,
    complexity: TaskComplexity,
    target_lang: Optional[str] = None,
) -> None:
    """Process and send response with progress updates."""
    
    if user_id not in user_audio_cache:
        await query.edit_message_text(MESSAGES["session_expired"])
        return
    
    audio_info = user_audio_cache[user_id]
    
    mode_names = {
        "transcript": "ğŸ“œ Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ",
        "lecture": "ğŸ“š Ø¯Ø±Ø³Ù†Ø§Ù…Ù‡",
        "soap": "ğŸ©º SOAP Ù¾Ø²Ø´Ú©ÛŒ",
        "summary_quick": "ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ø³Ø±ÛŒØ¹",
        "summary_detailed": "ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹",
        "lyrics": "ğŸµ Ù…ØªÙ† Ø¢Ù‡Ù†Ú¯",
        "translate_quick": "ğŸŒ ØªØ±Ø¬Ù…Ù‡ Ø³Ø±ÛŒØ¹",
        "translate_detailed": "ğŸŒ ØªØ±Ø¬Ù…Ù‡ Ø¯Ù‚ÛŒÙ‚",
    }
    
    current_stage = "stt"
    
    async def update_progress(stage: str, progress: int):
        nonlocal current_stage
        current_stage = stage
        
        if stage == "stt":
            msg = MESSAGES["processing_stt"].format(progress=progress)
        elif stage == "llm":
            if complexity == TaskComplexity.FAST:
                msg = MESSAGES["processing_llm_fast"].format(progress=progress)
            else:
                msg = MESSAGES["processing_llm_complex"].format(progress=progress)
        else:
            return
        
        try:
            await query.edit_message_text(
                f"ğŸ¯ **{mode_names.get(mode)}**\n\n{msg}",
                parse_mode="Markdown"
            )
        except Exception:
            pass  # Ignore rate limit errors
    
    try:
        # Initial progress
        await update_progress("stt", 0)
        
        # Process
        result = await process_audio_complete(
            audio_info["data"],
            audio_info["mime_type"],
            mode,
            complexity,
            target_lang=target_lang,
            progress_callback=update_progress,
        )
        
        if result["error"]:
            await query.edit_message_text(result["error"])
            return
        
        if not result["text"]:
            await query.edit_message_text(MESSAGES["error"])
            return
        
        # Build response
        detected_lang = result.get("detected_lang", "en")
        lang_info = LANGUAGES.get(detected_lang, LANGUAGES["en"])
        
        header = f"âœ… **{mode_names.get(mode)}**\n"
        header += f"ğŸ” Ø²Ø¨Ø§Ù† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡: {lang_info.flag} {lang_info.name_native}\n"
        
        if target_lang:
            target = LANGUAGES.get(target_lang)
            header += f"ğŸ¯ ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡: {target.flag} {target.name_native}\n"
        
        header += "\n"
        
        # Footer
        footer = f"\n\n---\nğŸ¤– Ù…Ø¯Ù„: `{result['model']}`"
        
        full_text = header + result["text"] + footer
        
        # Send main response
        if len(full_text) > 4000:
            # First chunk
            await query.edit_message_text(full_text[:4000], parse_mode="Markdown")
            
            # Remaining chunks
            remaining = full_text[4000:]
            while remaining:
                chunk = remaining[:4000]
                remaining = remaining[4000:]
                await asyncio.sleep(0.3)
                await context.bot.send_message(
                    chat_id=query.message.chat_id,
                    text=chunk,
                    parse_mode="Markdown"
                )
            
            # Send back button separately
            await context.bot.send_message(
                chat_id=query.message.chat_id,
                text=MESSAGES["operation_complete"].format(mode=mode_names.get(mode)),
                reply_markup=get_back_to_menu_keyboard(),
                parse_mode="Markdown"
            )
        else:
            await query.edit_message_text(full_text, parse_mode="Markdown")
            
            # Send back button
            await context.bot.send_message(
                chat_id=query.message.chat_id,
                text=MESSAGES["operation_complete"].format(mode=mode_names.get(mode)),
                reply_markup=get_back_to_menu_keyboard(),
                parse_mode="Markdown"
            )
    
    except Exception as e:
        logger.error(f"Process error: {e}")
        logger.error(traceback.format_exc())
        await query.edit_message_text(f"âŒ Ø®Ø·Ø§: {str(e)[:100]}")
    
    finally:
        # Clear state but KEEP audio cache!
        user_state.pop(user_id, None)


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.error(f"Error: {context.error}")
    logger.error(traceback.format_exc())


# ============== MAIN ==============
def main() -> None:
    print("\n" + "=" * 70)
    print("  ğŸ§ OMNI-HEAR AI v7.0 - AssemblyAI + Groq Edition")
    print("  ğŸ¤ AssemblyAI STT | âš¡ Llama 8B | ğŸ§  Llama 70B")
    print("=" * 70)
    
    if not TELEGRAM_BOT_TOKEN:
        print("âŒ TELEGRAM_BOT_TOKEN not set!")
        sys.exit(1)
    
    if not ASSEMBLYAI_API_KEY:
        print("âŒ ASSEMBLYAI_API_KEY not set!")
        sys.exit(1)
    
    if not GROQ_API_KEY:
        print("âŒ GROQ_API_KEY not set!")
        sys.exit(1)
    
    print(f"âœ… Telegram: Ready")
    print(f"âœ… AssemblyAI: Ready")
    print(f"âœ… Groq: Ready")
    print(f"\nğŸ¤– Models:")
    print(f"   â€¢ Fast: {GROQ_MODEL_FAST}")
    print(f"   â€¢ Complex: {GROQ_MODEL_COMPLEX}")
    print(f"\nğŸŒ Languages: {', '.join([l.flag for l in LANGUAGES.values()])}")
    print("=" * 70 + "\n")
    
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("status", status_command))
    app.add_handler(MessageHandler(
        filters.VOICE | filters.AUDIO | filters.Document.AUDIO,
        handle_audio
    ))
    app.add_handler(CallbackQueryHandler(button_callback))
    app.add_error_handler(error_handler)
    
    logger.info("ğŸš€ Starting bot...")
    app.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)


if __name__ == "__main__":
    main()
